---
title: "Análisis Multivariable para Procedimientos de Control Estadístico de Procesos Fisicoquímicos"
---

## ¿Cómo, por qué, para qué y de dónde surge el análisis multivariable?

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

**Este sitio está dirigido a ingenieros, químicos y especialistas técnicos que trabajan con procesos fisicoquímicos complejos y requieren algo más que herramientas o algoritmos: requieren comprensión estructural, validación estadística y control multivariable científicamente legítimo y sobe todo: [auditable.]{.underline}**

Aquí no se presentan recetas rápidas ni enfoques basados únicamente en software. El punto de partida es más fundamental: entender que el control de un proceso multivariable no depende de variables aisladas, sino de la estructura estadística que las conecta.

Desde esa premisa, este sitio aborda el análisis multivariable como lo que realmente es: una disciplina fundamentada en la identificación de grados de libertad, en la estructura de covarianza de los datos y en el subespacio donde emerge el significado físico del proceso.

\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

Los procesos fisicoquímicos son, por naturaleza, **multivariables**.

Para el lector que busca comprender qué es realmente el *análisis multivariable* aplicado al proceso industrial, es necesario considerar antes algo mucho más fundamental.

Un fenómeno multivariable **no vive en las variables**. \
Vive en la **estructura de covarianza** que las conecta.

Esto puede sonar extraño al inicio, pero la realidad (y por tanto el control) de un proceso multivariable **no reside en las variables individuales**, sino en el **subespacio** que estas conforman.

Ese subespacio es un lugar físico e intelectual al mismo tiempo.

No se observa directamente con los ojos, sino que se reconstruye con la mente y con matemáticas. Las variables fisicoquímicas, cuando se capturan como *datos*, no son el fenómeno en sí: son manifestaciones parciales de una expresión más esencial, una estructura que filtra la confusión para revelar significado.

Ese significado solo puede encontrarse en el subespacio que contiene la expresión mínima y fundamental del objeto central que es el que en realidad se analiza y el que más interesa, porque es el que está en el fondo del asunto: **el grado de libertad**.

Un grado de libertad hace tres cosas esenciales:

1.  Contiene la variación natural del proceso

2.  La separa en componentes independientes

3.  Nos muestra cómo se comporta el sistema

Un proceso real no tiene un solo grado de libertad.

El subespacio contiene varios. Algunos son indispensables; otros, irrelevantes. La diferencia es crucial: los principales contienen la información esencial para comprender, diagnosticar y decidir; el resto es redundancia o ruido.

Ese subespacio tiene nombre. \
Tiene valores. \
Y tiene vectores.

Es el **subespacio eigen**.

El análisis multivariable con base científica aplicado a procesos industriales **comienza formalmente ahí**.

Y de eso es exactamente de lo que hablaremos en este sitio.

Le damos la bienvenida.

### Vayamos a los detalles

El control estadístico multivariable (MSPC) difiere del control univariable tradicional (SPC).

No es “mejor” ni “peor”; es **conceptualmente distinto** y responde a una lógica diferente.

### Una analogía simple

Un procedimiento de control **univariable** puede compararse con un **detector de humo**:\
indica que el fuego existe, pero lo hace **después** de que la ignición ya ocurrió.

Un procedimiento de control **multivariable** es más parecido a un **detector infrarrojo de temperatura**:\
detecta incrementos simultáneos en distintos puntos **antes** de que se alcance el punto de ignición.

Ambos enfoques son útiles.

La diferencia es que el segundo detecta cambios y tendencias más rápido porque contiene y procesa mucha más información. ¿Cómo?

**Analiza las interacciones internas a partir de la covarianza del sistema**, mientras que el primero las ignora. Nunca las toca.

Por ello, el análisis multivariable es **más sensible e informativo**, especialmente para procesos fisicoquímicos complejos.

## Fluctuación, estructura y control

Los datos multivariables **siempre exhiben fluctuaciones interconectadas**.

Para construir procedimientos de control estadísticamente legítimos, existe **una sola pregunta analítica con validez científica**:

**¿Esas fluctuaciones están estructuradas en grados de libertad dominantes, o son esencialmente ruido?**

La respuesta la proporciona el **análisis eigen**.

Y la base es el álgebra lineal. Todo el análisis y la tecnología para extraer las respuestas están ahí.

Lo siguiente que veremos puede sonar "teórico" pero en realidad, es la base fundamental del análisis de datos y depende de la identificación de **los grados de libertad** de un sistema multivariable que pudiese o no contener información.

Cada grado de libertad queda descrito como un valor eigen $\lambda_i$ que cuantifica la varianza asociada a su respectivo grado de libertad independiente del sistema, mientras que los vectores eigen correspondientes definen las direcciones ortogonales de fluctuación en el espacio de las variables originales.

Las expresiones formales que definen y explican estos conceptos adquieren la forma del álgebra lineal y todo comienza con la matriz de nuestros de datos de proceso, $\boldsymbol{X}$ y su respectiva matriz de covarianza $\boldsymbol{\Sigma}$, descompuesta en sus vectores eigen $\boldsymbol{P}$ y sus grados de libertad $\boldsymbol{\Lambda}$.

#### $$\boldsymbol{\Sigma} = \mathbf{P}\boldsymbol{\Lambda}\mathbf{P}^\top$$

Digamos que $\mathbf{X} \in \mathbb{R}^{n \times m}$ es nuestra matriz de datos multivariables de calibración en Fase I, centrada y escalada.

Luego, tenemos su matriz de covarianzas:

#### $$\boldsymbol{\Sigma} = \frac{1}{n-1}\mathbf{X}^\top \mathbf{X}$$

Por eso el análisis eigen consiste simplemente en resolver la ecuación característica:

#### $$\det(\boldsymbol{\Sigma} - \lambda \mathbf{I}) = 0$$

La física clásica nos enseñó que esta determinante nos entrega las raíces $\lambda_1 \ge \lambda_2 \ge \dots \ge \lambda_p$ que definen la cantidad y magnitud de cada uno de los modos elementales de fluctuación material de nuestro proceso, siempre y cuando se encuentre en el equilibrio. Esto es simple de entender porque se supone que esa es la condición de nuestro proceso cuando está bajo control y el producto es conforme.

En términos prácticos: podremos tener 5, 50 o 500 variables o más en nuestro proceso, (inclusive autocorrelacionadas en el tiempo) pero si la información está intercorrelacionada, o si fuera redundante o multicolineal, no tendremos que descartar nada porque con solo un puñado de modos elementales obtendremos toda la información que necesitamos para establecer el control estadístico del proceso con la mayor sensibilidad posible.

Esto es justo lo que nos revela la distribución de todas las variaciones: el 100% de toda la fluctuación está repartida entre cada uno de los grados de libertad.

¿Cómo procedemos?

## Dos caminos posibles

El resultado del análisis eigen permite decidir entre dos enfoques claramente diferenciados:

### 1. Metodologías trazables y validables

Lo primero es la proyección de una observación $\mathbf{x}$ sobre el subespacio definido por los modos dominantes. Al proyectar nuestras variables originales al subespacio ocupado por los grados de libertad, aparece la definición de una distancia estadística cuadrática conocida popularmente como Mahalanobis:

#### $$T^2 = \mathbf{x}^\top \boldsymbol{\Sigma}^{-1} \mathbf{x}$$

También se representa con la letra D y en algunos textos de quimiometría se escribe como h0. Es un escalar muy popular.

Este tipo de escalar nos permite medir la desviación global del sistema respecto a su estado de equilibrio, ubicado en el centro de la distribución de probabilidad, pero que ahora es multivariable y con forma elíptica (en el contexto univariable es la clásica curva gaussiana). Es el mismo origen en el espacio euclidiano multidimensional, pero que al escalarlo y maniobrar con la rotación de los ejes, tansitamos al espacio donde encontramos a los grados de libertad que caracterizan a nuestro sistema y ahí es donde fluctúan con independencia. El sistema no cambió. Lo único que cambió fue nuestro ángulo de observación. Y toda la información de fluctuación se conserva. Nada se pierde. Pero todo se simplifica.

Por eso el desarrollo de metodologías estocásticas multivariables para control de procesos fisicoquímicos se fundamentan en:

-   distancias estadísticas,

-   regiones de probabilidad con límites naturales,

-   pruebas de hipótesis falsables,

-   control explícito del error tipo I.

Este enfoque es compatible con **control estadístico multivariable de procesos** y validación científica formal porque toda su matemática es transparente y auditable.

### 2. Modelado algorítmico sin trazabilidad

Lo segundo es recurrir a algoritmos de *machine learning* para modelar patrones locales de la fluctuación, pero **sin ninguna garantía de trazabilidad matemática ni validación estadística formal**. El aprendizaje de máquina no constituye una metodologóia de validación porque para efectos de trazabilidad, es una "caja negra".

Ambos caminos son legítimos, pero **no persiguen el mismo objetivo**.

## Madurez del proceso y validez estadística

Bajo condiciones de normalidad multivariable y estabilidad del proceso, el estadístico $T^2$ sigue una distribución conocida, lo que permite establecer **regiones elípticas de probabilidad** y formular pruebas de hipótesis falsables para el control del error tipo I.

#### $$H_0: T^2 \le T^2_{\text{crit}} \qquad H_1: T^2 > T^2_{\text{crit}}$$

Este procedimiento exige visualizar la normalidad multivariable en la forma de su distribución de probabilidad que emerge de manera natural: la elipse (o elipsoide).

Haz clic sobre la siguiente imagen, rótala , muévela, haz scroll y acércate y aléjate y explora.

```{r}

#| echo: false
#| warning: false
#| message: false
#| results: hide
#| cache: false
#| fig-cap: "Región elipsoidal de probabilidad asociada al estadístico T^2."

library(rgl)
library(MASS)
library(car)  # para ellipse3d

# --- Matriz de covarianzas ---
Sigma <- matrix(c(10, 3, 0,
                  3,  2, 0,
                  0,  0, 1), 3, 3)

# --- Media y datos simulados ---
Mean <- 1:3
set.seed(123)
x <- MASS::mvrnorm(1000, Mean, Sigma)

# --- Abrir ventana rgl embebida ---
open3d()
bg3d("white")

# --- Nube de datos ---
plot3d(x,
       col  = "gray40",
       size = 4,
       box  = FALSE,
       xlab = "",
       ylab = "",
       zlab = "",)

# --- Elipsoide de confianza (Hotelling T^2 implícito) ---
ell <- ellipse3d(Sigma, centre = Mean, level = 0.95)
shade3d(ell, col = "#265129", alpha = 0.35)

# --- Ejes y aspecto ---
axes3d()
aspect3d(1, 1, 1)

# --- Etiquetas de ejes sin acentos ni saltos de linea ---
title3d(
  xlab = "Eigen 1",
  ylab = "Eigen 2",
  zlab = "Eigen 3",
  main = "Region elipsoidal de probabilidad Hotelling T2 (95%)"
)

# --- Embebido para Quarto ---
rglwidget()
```

Cada punto es una observación en una tabla de datos multivariables, pero nuestro procedimiento colapsa todos los datos en puntos que se ubican en coordenadas que obedecen a los grados de libertad eigen dominantes. Cada grado de libertad eigen representa conjuntos de variables.

La superficie translúcida representa la región de probabilidad del 95% asociada al estadístico T².

Por eso todos los puntos que están dentro de la elipse son observaciones conformes y las que están fuera de ella son no conformidades en la región $\alpha = 0.05$.

La idea es equivalente a un gráfico de control univariable. Es solo que en este formato y con esta metodología, cada punto puede contener docenas o cientos de variables, todas condensadas en un punto en el espacio.

La elipse no es una elección gráfica: es la manifestación directa de la estructura espectral de la matriz de covarianzas. Sin modos eigen dominantes, esta región no existe.

Por eso, si el cliente requiere la **primera vía** (validación científica de sus datos multivariables), pero el análisis eigen revela **ausencia de modos dominantes**, ello indica que:

-   el proceso aún no ha alcanzado la **madurez y estabilidad necesarias**, y

-   **no existen grados de libertad mínimos suficientes** para una validación estadística legítima.

Pretender control estadístico multivariable bajo condiciones no estructuradas **no es válido**.

## ¿Qué se busca confirmar?

Si su objetivo es implementar un procedimiento de control multivariable fundamentado en la física del sistema, es indispensable confirmar:

1.  **Si existen grados de libertad dominantes**, y

2.  **Si existen en cantidad mínima aceptable**.

### ¿Por qué?

Porque:

**Sin grados de libertad dominantes, el control estadístico multivariable no es ni física ni matemáticamente posible.**

**Y sin control estadístico multivariable a partir de un proceo maduro y estable, no existe validación falsable del error tipo I.**

Si los datos carecen de estructura espectral dominante, la única alternativa razonable es modelar la fluctuación **localmente**, mediante algoritmos de machine learning. La búsqueda de algoritmos útiles es laboriosa y toma tiempo porque requiere comparaciones empíricas, a prueba y error bajo criterios arbitrarios o en el mejor de los casos, de validaciones cruzadas, hasta encontrar alguno que pudiera modelar el ruido generalizado. En todos los casos, la selección final depende no solo de las pruebas, sino del criterio subjetivo del analista. Por eso las metodologías con algoritmos de machine learning difícilmente son reproducibles.

Naturalmente, la seria desventaja es que en estos casos no es posible ni factible establecer procedimientos de control a partir de validación estadística.

## Beneficio para el cliente

Cuando los datos fisicoquímicos multivariables **sí revelan estructura interna**, el beneficio es doble:

1.  Es posible implementar control estadístico multivariable **de alta sensibilidad**.

2.  Se habilita la **identificación de causas raíz**.

¿Por qué?

Porque la señal multivariable está compuesta por **señales univariables interconectadas**.\
Cuando se detecta una desviación multivariable, **al menos una o dos variables** son responsables.\
Así, aunque sean docenas o incluso cientos, la descomposición quimiométrica de la señal permite **identificarlas y cuantificarlas**. Una por una. Con un clic.

Por eso el desarrollo de metodologías por estadística multivariable a partir de la descomposición espectral eigen para identificación de grados de libertad no solo es reproducible, sino trazable.

Por eso es científica.

## Nuestra labor

Nuestra labor es simple y fundamental:

**Determinar si un proceso fisicoquímico es maduro, estable y estadísticamente validable.**

¿Cómo lo hacemos?

**Identificando los modos elementales de fluctuación que emergen a partir del análisis eigen de sus datos fisicoquímicos multivariables.**

El objetivo final es contar con un procedimiento de control que permita detectar desviaciones tempranas y en cuestión de segundos, conocer las causas.

Todo inicia con el análisis eigen que identifica los grados de libertad en sus datos.

Y todo termina con el diagnóstico de causas-raíz. Con solo un clic.
