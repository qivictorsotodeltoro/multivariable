[
  {
    "objectID": "T2_Q.html",
    "href": "T2_Q.html",
    "title": "Exploración Multivariada - T2 de Hotelling Vs Q de Jackson",
    "section": "",
    "text": "El gráfico T² (horizontal) vs Q (vertical) es un gráfico de control que condensa el estado completo de un sistema multivariable, en un solo punto, por observación. Da igual si el proceso tiene 5 o 300 o más variables: aquí todas ellas se colapsan y resumen en solo dos distancias estadísticas.\nEl principio fundamental es uno solo: queremos que todas las observaciones permanezcan cercanas al origen estadístico del sistema, definido por el modelo multivariable calibrado. Eso es lo más importante.\nLas desviaciones comienzan a manifestarse cuando cada observación se aleja del origen, tanto en T² como en Q.\nPor eso este gráfico de control es tan útil y simple de entender.\nMueva el cursor, obtenga lecturas individuales, haga clic y arrastre el mouse, utilice zoom in y zoom out, y restaure la visualización utilizando las opciones del menú automático de exploración ubicado en la esquina superior derecha del gráfico.\nLos detalles analíticos vienen debajo del gráfico.\n\n\n\n\n\n\n\n\nT² mide qué tan lejos está una observación del centro del proceso, pero solo en las direcciones donde el sistema realmente varía.\nEs una distancia multivariable tipo Mahalanobis, calculada en el subespacio dominante del sistema (eigenestructura).\nUn T² alto indica variación estructurada: el proceso se mueve de forma extrema, pero coherente con su física.\n\n\n\nQ (Squared Prediction Error) mide lo que queda fuera del modelo, la variación no explicada por la estructura dominante.\nUn Q alto indica comportamiento anómalo: fallas, errores, perturbaciones externas o condiciones no modeladas.\nQ no mide intensidad del proceso; mide incongruencia estructural.\nPara decirlo coloquialmente: novedad, extrañeza, peculiaridad.\nY como estamos explorando un ejemplo de vinos:\n\\(\\boldsymbol{T^2}\\) elevado nos diría si un vino astringente es más astringente de lo habitual.\n\\(\\boldsymbol{Q}\\) elevado nos dice que, aunque un vino siga siendo astringente, si ahora presenta notas afrutadas y menor contenido alcohólico, ya no es el mismo vino. Es otro producto.\nSi \\(\\boldsymbol{T^2}\\) y \\(\\boldsymbol{Q}\\) son elevados, lo que ahora tenemos es un vino más astringente de lo habitual, además notas más afrutadas y menos alcohol: el cambio detectado es definitivamente radical.\nEn una competencia de premiación, este mismo vino podría ser rechazado por no ajustarse al perfil histórico de la denominación, o bien celebrado precisamente por romper ese perfil y proponer uno nuevo.\nEn el plano T²– Q, este tipo de observación aparece lejos del origen en ambas direcciones, señalando una no conformidad multivariable clara si ello resulta indeseable, o bien una innovación diferenciadora, si ese es el objetivo del sistema.\nEn cualquiera de los dos casos, la singularidad multivariable queda estadísticamente confirmada.\n\n\n\n\nT² bajo / Q bajo → Proceso bajo control\nT² alto / Q bajo → Variación extrema pero estructurada\nT² bajo / Q alto → Anomalía fuera del comportamiento normal\nT² alto / Q alto → No conformidad multivariable clara\n\nEste gráfico separa causas, no solo detecta desviaciones.\n\n\n\nAquí no aplica la lógica de ±1σ, ±2σ, ±3σ.\n¿Por qué?\nPorque T² y Q no son variables del proceso. Son distancias estadísticas cuadráticas multivariables.\nEso implica tres cosas fundamentales:\n\nNo tienen signo\nNo son simétricas\nNo existen límites inferiores\n\nEn análisis multivariable fisicoquímico no existen límites inferiores: solo existen límites superiores.\n\n\n\nEstos límites no son heurísticos ni empíricos.\nAl tratarse de distancias cuadráticas, sus umbrales provienen necesariamente de distribuciones estadísticas conocidas, bajo el supuesto de normalidad multivariable y calibración en Fase I:\n\nT²: distribuciones relacionadas con χ² o F\nQ: distribución derivada del espectro eigen del sistema\n\nDebemos tener presente que T² y Q no son nuestras variables: son los vehículos matemáticos que las contienen y las condensan.\nEsto solo puede ser así porque los límites T² y Q responden a (y emergen de) la covarianza del sistema completo. Y como sabemos, todas las varianzas de cada variable en una matriz de covarianzas son cantidades cuadráticas por naturaleza y por lo tanto, positivas.\nPor esa razón, intentar analizar T² o Q es incompatible con la lógica lineal-bidireccional de ±σ. Insistir en ello es conceptualmente incorrecto y matemáticamente inválido.\n\n\n\nCruzar un límite de T² o Q no significa que una observación “se vea rara”.\nSignifica que:\nSe ha violado una hipótesis estadística explícita, al nivel de significancia definido por el error tipo I.\nEn ese momento, el sistema deja de estar bajo control estadístico y las causas raíz deben investigarse.\nNo es intuición.\nNo es experiencia.\nEs inferencia estadística formal.\n\n\n\n\nSPC univariable solo hace esta pregunta: ¿una variable se salió de rango?\nControl multivariable hace esta: ¿el sistema completo sigue comportándose como un sistema físico estable?\n\nPor eso este gráfico T² - Q no es “una buena idea”.\nEs el mapa estándar del diagnóstico estadístico multivariable para procesos fisicoquímicos.\nPara construirlo, todo empieza con el análisis de la estructura eigen de nuestros datos históricos originales: si los grados de libertad naturales existen en el sistema histórico, solo entonces construir este gráfico será posible.\nSi esa estructura interna no existe, este gráfico no tiene sentido.\nSi existe, este gráfico es inevitable.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q",
      "3.1 Exploración General T² vs Q"
    ]
  },
  {
    "objectID": "T2_Q.html#gráfico-t²-vs-q-diagnóstico-multivariable-en-un-solo-plano",
    "href": "T2_Q.html#gráfico-t²-vs-q-diagnóstico-multivariable-en-un-solo-plano",
    "title": "Exploración Multivariada - T2 de Hotelling Vs Q de Jackson",
    "section": "",
    "text": "El gráfico T² (horizontal) vs Q (vertical) es un gráfico de control que condensa el estado completo de un sistema multivariable, en un solo punto, por observación. Da igual si el proceso tiene 5 o 300 o más variables: aquí todas ellas se colapsan y resumen en solo dos distancias estadísticas.\nEl principio fundamental es uno solo: queremos que todas las observaciones permanezcan cercanas al origen estadístico del sistema, definido por el modelo multivariable calibrado. Eso es lo más importante.\nLas desviaciones comienzan a manifestarse cuando cada observación se aleja del origen, tanto en T² como en Q.\nPor eso este gráfico de control es tan útil y simple de entender.\nMueva el cursor, obtenga lecturas individuales, haga clic y arrastre el mouse, utilice zoom in y zoom out, y restaure la visualización utilizando las opciones del menú automático de exploración ubicado en la esquina superior derecha del gráfico.\nLos detalles analíticos vienen debajo del gráfico.\n\n\n\n\n\n\n\n\nT² mide qué tan lejos está una observación del centro del proceso, pero solo en las direcciones donde el sistema realmente varía.\nEs una distancia multivariable tipo Mahalanobis, calculada en el subespacio dominante del sistema (eigenestructura).\nUn T² alto indica variación estructurada: el proceso se mueve de forma extrema, pero coherente con su física.\n\n\n\nQ (Squared Prediction Error) mide lo que queda fuera del modelo, la variación no explicada por la estructura dominante.\nUn Q alto indica comportamiento anómalo: fallas, errores, perturbaciones externas o condiciones no modeladas.\nQ no mide intensidad del proceso; mide incongruencia estructural.\nPara decirlo coloquialmente: novedad, extrañeza, peculiaridad.\nY como estamos explorando un ejemplo de vinos:\n\\(\\boldsymbol{T^2}\\) elevado nos diría si un vino astringente es más astringente de lo habitual.\n\\(\\boldsymbol{Q}\\) elevado nos dice que, aunque un vino siga siendo astringente, si ahora presenta notas afrutadas y menor contenido alcohólico, ya no es el mismo vino. Es otro producto.\nSi \\(\\boldsymbol{T^2}\\) y \\(\\boldsymbol{Q}\\) son elevados, lo que ahora tenemos es un vino más astringente de lo habitual, además notas más afrutadas y menos alcohol: el cambio detectado es definitivamente radical.\nEn una competencia de premiación, este mismo vino podría ser rechazado por no ajustarse al perfil histórico de la denominación, o bien celebrado precisamente por romper ese perfil y proponer uno nuevo.\nEn el plano T²– Q, este tipo de observación aparece lejos del origen en ambas direcciones, señalando una no conformidad multivariable clara si ello resulta indeseable, o bien una innovación diferenciadora, si ese es el objetivo del sistema.\nEn cualquiera de los dos casos, la singularidad multivariable queda estadísticamente confirmada.\n\n\n\n\nT² bajo / Q bajo → Proceso bajo control\nT² alto / Q bajo → Variación extrema pero estructurada\nT² bajo / Q alto → Anomalía fuera del comportamiento normal\nT² alto / Q alto → No conformidad multivariable clara\n\nEste gráfico separa causas, no solo detecta desviaciones.\n\n\n\nAquí no aplica la lógica de ±1σ, ±2σ, ±3σ.\n¿Por qué?\nPorque T² y Q no son variables del proceso. Son distancias estadísticas cuadráticas multivariables.\nEso implica tres cosas fundamentales:\n\nNo tienen signo\nNo son simétricas\nNo existen límites inferiores\n\nEn análisis multivariable fisicoquímico no existen límites inferiores: solo existen límites superiores.\n\n\n\nEstos límites no son heurísticos ni empíricos.\nAl tratarse de distancias cuadráticas, sus umbrales provienen necesariamente de distribuciones estadísticas conocidas, bajo el supuesto de normalidad multivariable y calibración en Fase I:\n\nT²: distribuciones relacionadas con χ² o F\nQ: distribución derivada del espectro eigen del sistema\n\nDebemos tener presente que T² y Q no son nuestras variables: son los vehículos matemáticos que las contienen y las condensan.\nEsto solo puede ser así porque los límites T² y Q responden a (y emergen de) la covarianza del sistema completo. Y como sabemos, todas las varianzas de cada variable en una matriz de covarianzas son cantidades cuadráticas por naturaleza y por lo tanto, positivas.\nPor esa razón, intentar analizar T² o Q es incompatible con la lógica lineal-bidireccional de ±σ. Insistir en ello es conceptualmente incorrecto y matemáticamente inválido.\n\n\n\nCruzar un límite de T² o Q no significa que una observación “se vea rara”.\nSignifica que:\nSe ha violado una hipótesis estadística explícita, al nivel de significancia definido por el error tipo I.\nEn ese momento, el sistema deja de estar bajo control estadístico y las causas raíz deben investigarse.\nNo es intuición.\nNo es experiencia.\nEs inferencia estadística formal.\n\n\n\n\nSPC univariable solo hace esta pregunta: ¿una variable se salió de rango?\nControl multivariable hace esta: ¿el sistema completo sigue comportándose como un sistema físico estable?\n\nPor eso este gráfico T² - Q no es “una buena idea”.\nEs el mapa estándar del diagnóstico estadístico multivariable para procesos fisicoquímicos.\nPara construirlo, todo empieza con el análisis de la estructura eigen de nuestros datos históricos originales: si los grados de libertad naturales existen en el sistema histórico, solo entonces construir este gráfico será posible.\nSi esa estructura interna no existe, este gráfico no tiene sentido.\nSi existe, este gráfico es inevitable.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q",
      "3.1 Exploración General T² vs Q"
    ]
  },
  {
    "objectID": "referencias.html",
    "href": "referencias.html",
    "title": "Fuentes Bibliográficas",
    "section": "",
    "text": "El autor de este sitio insiste en un punto fundamental: ninguno de los contenidos aquí presentados constituye conocimiento nuevo ni original. Este espacio funciona deliberadamente como un resumen técnico estructurado, cuyo objetivo es orientar al lector hacia las fuentes originales donde se desarrollan, con rigor completo, los fundamentos teóricos y metodológicos del análisis multivariable aplicado a procesos fisicoquímicos industriales.\nLas referencias enlistadas a continuación representan textos y artículos que han definido (y continúan definiendo) la práctica profesional de la quimiometría, el control estadístico multivariable de procesos y la tecnología analítica aplicada a la industria.\nReferencias principales\n\nMartens, H., & Næs, T. (1989). Multivariate Calibration (1st ed.). Wiley.\nBakeev, K. A. (Ed.). (2010). Process Analytical Technology: Spectroscopic Tools and Implementation Strategies for the Chemical and Pharmaceutical Industries (2nd ed.). Wiley.\nMiller, J. N., & Miller, J. C. Statistics and Chemometrics for Analytical Chemistry (6th ed.). Pearson.\nKourti, T., & MacGregor, J. F. (1996). Multivariate SPC Methods for Process and Product Monitoring. Journal of Quality Technology, 28(4), 409–428.\nDOI: 10.1080/00224065.1996.11979699\nJackson, J. E. (1991). A User’s Guide to Principal Components (1st ed.). Wiley.\nMason, R. L., & Young, J. C. Multivariate Statistical Process Control with Industrial Applications. SIAM.\nJohnson, R. A., & Wichern, D. W. Applied Multivariate Statistical Analysis (6th ed.). Pearson.\n\nExisten muchas más referencias relevantes en la literatura técnica y académica. Sin embargo, el autor ha optado por enlistar únicamente aquellas que atienden de manera directa los intereses inmediatos del lector que desea iniciarse (o reinsertarse con rigor) en la aplicación del análisis multivariable a procesos químicos industriales en operación real.\nEstas obras no se recomiendan por su novedad editorial, sino por su estabilidad conceptual, profundidad metodológica y utilidad comprobada en contextos industriales, donde las decisiones deben ser defendibles, auditables y sostenibles en el tiempo."
  },
  {
    "objectID": "parcoord.html",
    "href": "parcoord.html",
    "title": "Exploración Multivariada - Gráfico de Coordenadas Paralelas",
    "section": "",
    "text": "A continuación presentamos un gráfico de coordenadas paralelas para el análisis multivariable de datos fisicoquímicos de vinos italianos.\nLe invitamos a explorar el gráfico de manera interactiva:\nMueva el cursor, obtenga lecturas individuales, haga clic y arrastre el mouse, utilice zoom in y zoom out, y restaure la visualización utilizando las opciones del menú automático de exploración ubicado en la esquina superior derecha del gráfico.\nLa explicación detallada de la visualización se presenta debajo del gráfico.\n\n\n\n\n\n\nEn el eje horizontal se muestran todas las variables que conforman el control de las características de calidad del producto. En el eje vertical se representan sus magnitudes estandarizadas.\nCada línea corresponde a un lote de producto.\nLas líneas en color gris representan observaciones típicas dentro del grupo de referencia.\nEn color verde se muestra un lote que, si bien sigue el patrón general, presenta una o más variables que han cruzado umbrales naturales del sistema, lo que provoca que el lote completo se desvíe del patrón colectivo esperado.\nEn color amarillo se muestran dos observaciones que no encajan en ninguna estructura típica. Se trata de dos lotes que constituyen outliers multivariables.\nPara profundizar en las métricas multivariables empleadas por nuestro método quimiométrico para el monitoreo de variables fisicoquímicas, invitamos al lector a explorar los siguientes gráficos:\n\n\\(T^2 \\; vs \\;Q\\) en la sección 3.1\n\\(T^2\\) en la sección 3.2\n\\(Q\\) en la sección 3.3\n\nAllí veremos cómo se deben leer y entender los gráficos de estos métricos en el control estadístico de procesos multivariables (MSPC) fisicoquímicos.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "2. Diagnóstico Compuesto",
      "2.1 Gráfico Coordinado Paralelo"
    ]
  },
  {
    "objectID": "marco_teorico.html",
    "href": "marco_teorico.html",
    "title": "La Relación Entre Fisicoquímica Industrial Y Estadística Multivariable",
    "section": "",
    "text": "Este espacio está dedicado a las y los profesionales de la química aplicada a procesos industriales que enfrentan, de manera cotidiana, tres responsabilidades fundamentales:\nNada de lo que aquí se presenta es una idea original. Todo está ampliamente documentado en la literatura científica y técnica, y el lector podrá consultar y verificar cada afirmación. El objetivo de este trabajo es únicamente condensar, ordenar y hacer operativa la escuela de pensamiento de la quimiometría aplicada a procesos fisicoquímicos de transformación."
  },
  {
    "objectID": "marco_teorico.html#qué-es-la-quimiometría",
    "href": "marco_teorico.html#qué-es-la-quimiometría",
    "title": "La Relación Entre Fisicoquímica Industrial Y Estadística Multivariable",
    "section": "1 ¿Qué es la quimiometría?",
    "text": "1 ¿Qué es la quimiometría?\nEl término quimiometría fue acuñado hace varias décadas para describir una forma particular de analizar datos fisicoquímicos, en la que se combinan de manera explícita el pensamiento estadístico y el pensamiento químico.\nPermítase al lector aceptar la siguiente definición operativa (no académica):\nLa quimiometría es la aplicación de métodos estadísticos multivariables a modelos empíricos construidos a partir de datos fisicoquímicos.\nEl énfasis en la modelación empírica indica una preferencia deliberada por modelos derivados de datos estocásticos observados, en contraste con modelos puramente deterministas deducidos exclusivamente de teorías fisicoquímicas formales.\nEsto no implica que el conocimiento químico previo ni las teorías fundamentales sean ignoradas o relegadas. Significa, simplemente, que no constituyen por sí solas una base suficiente para la construcción de modelos operativos, especialmente cuando el sistema real exhibe complejidad, variabilidad inherente e interacciones no previstas por la teoría de sistemas ideales ni por enfoques estrictamente deterministas.\n\n1.1 Poder y riesgos de la quimiometría\nLa combinación de modelación empírica y análisis estadístico multivariable convierte a la quimiometría en una disciplina extraordinariamente poderosa, aunque no exenta de riesgos.\nSu principal fortaleza radica en la capacidad de modelar sistemas complejos y parcialmente desconocidos sin quedar limitada por supuestos teóricos rígidos. Esta característica representa una ventaja decisiva cuando el proceso presenta desviaciones significativas, interacciones no anticipadas o comportamientos que nunca fueron contemplados dentro de un marco estrictamente determinista.\nNo obstante, este poder analítico conlleva un costo metodológico bien definido:\n\nLa mayoría de los métodos multivariables requieren grandes volúmenes de datos confiables, representativos y de calidad consistente, así como una selección cuidadosa y sistemática de las variables que conforman el sistema analítico.\nLos modelos empíricos solo pueden aplicarse con seguridad dentro del dominio de condiciones efectivamente representado en los datos de calibración; cualquier intento de extrapolación fuera de ese dominio constituye una práctica inherentemente riesgosa.\nLa disponibilidad simultánea de múltiples variables de entrada y de respuesta introduce una fuerte tentación al sobreajuste, particularmente cuando se persiguen resultados aparentemente “óptimos” que carecen de robustez fuera del conjunto de datos utilizado para construir el modelo.\nFinalmente, los modelos multivariables suelen presentar dificultades de interpretación, especialmente cuando se comunican a audiencias con formación limitada en matemáticas, estadística o análisis multivariable.\n\nPor estas razones, la quimiometría no es una herramienta trivial ni automática. Su aplicación exige criterio científico, disciplina metodológica y un alto grado de responsabilidad profesional.\n\n\n1.2 Un poco de contexto histórico\nEl uso de la estadística multivariable con el propósito de analizar y comprender datos multivariables se remonta a la década de 1930, con los trabajos pioneros de Harold Hotelling. Aunque estas metodologías encontraron aplicaciones tempranas en diversos campos científicos, su adopción dentro de la química fue relativamente lenta.\nLa quimiometría como disciplina no se consolidó sino hasta las décadas de 1960 y 1970. Durante los años ochenta y noventa, su aplicación se concentró principalmente en el análisis de datos provenientes de tecnologías espectroscópicas, periodo en el cual se establecieron las bases metodológicas que hoy sustentan el análisis multivariable moderno en química industrial y en la fabricación de productos de consumo.\nEn la actualidad, las aplicaciones de la quimiometría se han extendido de manera significativa hacia la Tecnología Analítica de Procesos (Process Analytical Technology, PAT) y hacia una amplia variedad de industrias de transformación fisicoquímica. Sin embargo, muchas de estas aplicaciones permanecen escasamente documentadas en la literatura abierta y en artículos de investigación académica, principalmente por razones de confidencialidad industrial, aunque existe un motivo adicional.\nAl tratarse de procedimientos estandarizados definidos desde el siglo pasado, ni el sector académico ni el sector industrial suelen considerarlos como fuentes de novedad metodológica dignas de mayor divulgación. Su valor no reside en la innovación conceptual, sino en su madurez, estabilidad y eficacia probada.\nA pesar de esta baja visibilidad editorial y de su aparente obsolescencia metodológica, la quimiometría representa hoy la forma especializada y prevaleciente del análisis estadístico multivariable aplicada al monitoreo y diagnóstico de procesos fisicoquímicos. Su adopción es particularmente relevante para científicos analíticos e ingenieros que buscan sostener la mejora continua mediante procedimientos cada vez más rigurosos, trazables y confiables.\nPara ilustrarlo: aunque las matemáticas y la química cuentan con siglos de desarrollo, su valor no radica en la novedad técnica ni en modas metodológicas pasajeras, sino en su estabilidad histórica y en su capacidad comprobada para ofrecer el mayor grado posible de transparencia cuantitativa. Esta cualidad resulta esencial en sistemas y procedimientos analíticos que deben procesar volúmenes crecientes de información numérica, no necesariamente porque los procesos sean más complejos, sino porque las exigencias de control, validación y escrutinio se han vuelto progresivamente más estrictas."
  },
  {
    "objectID": "marco_teorico.html#algo-de-filosofía-industrial",
    "href": "marco_teorico.html#algo-de-filosofía-industrial",
    "title": "La Relación Entre Fisicoquímica Industrial Y Estadística Multivariable",
    "section": "2 Algo de filosofía industrial",
    "text": "2 Algo de filosofía industrial\nLa quimiometría no es una ciencia: es una tecnología. Y, además, una tecnología singular.\nLa mayoría de las tecnologías de base científica siguen una trayectoria relativamente clara: se conciben y desarrollan en instituciones académicas, posteriormente se transfieren a la industria y, finalmente, son adaptadas para aplicaciones prácticas por ingenieros y científicos industriales.\nLa quimiometría siguió un camino distinto.\nEn su desarrollo, la industria desempeñó un papel central. Muchas de sus herramientas no surgieron de la búsqueda de elegancia teórica ni de formalismo académico, sino de una necesidad urgente de aplicación práctica en contextos reales de producción. Su evolución estuvo guiada por problemas operativos concretos: variabilidad, complejidad, correlación entre variables y necesidad de diagnóstico confiable.\nEsta característica ha llevado a que algunas instituciones académicas hayan minimizado o eclipsado la quimiometría, argumentando que carece de fundamentos teóricos sólidos o que viola principios establecidos del análisis estadístico clásico. Sin embargo, este juicio contrasta con un hecho difícil de ignorar: la quimiometría demuestra diariamente su eficacia en una amplia gama de aplicaciones industriales, donde la validación no ocurre en el aula, sino en la operación continua de procesos industriales que producen los bienes que todos utilizamos.\nBajo la enseñanza de Svante Wold (nieto del ilustre Svante Arrhenius), Martens y Næs ofrecen una definición particularmente esclarecedora al describir la quimiometría como “una combinación del pensamiento químico y el pensamiento estadístico”. Esta síntesis no es trivial y explica tanto su potencia como las tensiones que genera.\nDesde esta perspectiva, los especialistas en estadística pura suelen ser plenamente conscientes de las capacidades y limitaciones formales de las herramientas estadísticas. Sin embargo, con frecuencia permanecen confinados a estructuras metodológicas rígidas, en las que el conocimiento químico del sistema desempeña un papel marginal. Para el estadístico puro, el diseño experimental, la modelación de datos o la interpretación de resultados rara vez incorporan aportes sustantivos de la fisicoquímica del proceso.\nPor otro lado, los químicos e ingenieros de procesos no siempre dominan las limitaciones teóricas del diseño experimental o del análisis estadístico, pero poseen el conocimiento fisicoquímico profundo necesario para diseñar experimentos relevantes, reconocer comportamientos anómalos, proponer hipótesis que ahorren tiempo y recursos, anticipar la plausibilidad física de los resultados y, en muchos casos, prevenir accidentes y siniestros.\nLa experiencia ha demostrado que ninguno de estos enfoques es suficiente por sí solo. El pensamiento químico y el pensamiento estadístico deben coexistir y colaborar para producir modelos que no solo sean matemáticamente correctos, sino útiles, interpretables y operativamente válidos.\nLa naturaleza empírica y eminentemente práctica de la quimiometría ha llevado a algunos observadores externos a concluir, de manera errónea, que quienes la practican no comprenden las herramientas que utilizan ni los modelos que desarrollan. En realidad, ocurre exactamente lo contrario: la quimiometría exige una comprensión simultánea del sistema fisicoquímico y del marco estadístico, precisamente porque sus resultados están obligados, por leyes, normas y contratos, a sostenerse frente a la realidad material del proceso y frente al beneficio que debe rendirle al consumidor.\nSi los métodos quimiométricos fueran insuficientes, inaplicables o innecesarios, las no conformidades se manifestarían a simple vista, sin que los datos de monitoreo tuvieran que revelarlas.\nEl desenlace sería inevitable: el cliente terminaría rechazando el producto o, peor aún, aceptándolo, pagándolo y consumiéndolo, para después quejarse o sufrir los efectos adversos de un producto que aparenta ser conforme, pero que resulta defectuoso cuando se analiza bajo el estricto escrutinio de un microscopio matemático.\nLa quimiometría (y sus versiones adaptadas a datos de proceso) no existe para detectar defectos obvios y evidentes. En ese escenario, su aplicación sería irrelevante.\nSu propósito es otro: detectar desviaciones sutiles, cuando las diferencias son pequeñas, no evidentes y estadísticamente invisibles para los métodos convencionales de análisis univariable, pero marcadamente obvias para los métodos multivariables.\n\n2.1 ¿Por qué la quimiometría puede evitar controversias cuando los métodos estadísticos clásicos no son suficientes?\nLa razón es simple: la información crítica (variaciones pequeñas pero potencialmente desastrosas) no reside en las variables aisladas, sino en la interacción, correlación, covarianza y multicolinealidad que con frecuencia permanecen ocultas. Estas estructuras de dependencia existen entre las variables operativas del proceso (variables de entrada) y, de manera inseparable, con las características de calidad del producto (variables de salida).\nDesde hace décadas, la práctica de la química industrial ha reconocido que los métodos estadísticos clásicos basados en el análisis univariable (e incluso muchos enfoques multivariables convencionales o superficialmente “modernizados”) no son capaces de detectar ni procesar estas estructuras de variación de forma que produzcan resultados simultáneamente confiables, interpretables y accionables.\nEl problema no es la falta de datos. El problema es la incapacidad de dichos métodos para representar adecuadamente la geometría real de un sistema multivariable.\nLa quimiometría surge precisamente para atender esta limitación operativa fundamental. Su propósito no es reemplazar el juicio químico ni imponer formalismos matemáticos innecesarios, sino proporcionar un marco analítico capaz de capturar, cuantificar y vigilar las relaciones vinculantes entre múltiples variables que evolucionan de manera conjunta.\nTodo químico lo sabe: el cambio de estado de las variables nunca ocurre de forma independiente. Por ello, el supuesto estadístico de independencia rara vez (si es que alguna vez) se cumple en sistemas fisicoquímicos reales. Esperar a que se cumpla solo para que los métodos univariables puedan aplicarse no es rigor metodológico, sino una concesión artificial a modelos que no describen la realidad.\nLo mismo ocurre con la autocorrelación. La cinética química es una propiedad intrínseca de toda transformación de la materia sometida a cualquier forma de energía, sencillamente porque (a excepción de las reacciones instantáneas), los procesos químicos industriales, además de ser multivariables, ocurren en el tiempo. Ignorar esta dimensión equivale a renunciar a una parte esencial de la información del sistema.\nEl trabajo de MacGregor aborda esta necesidad de manera sistemática y rigurosa. Su contribución representa la culminación operativa de una línea intelectual que Pearson inició, Hotelling refinó, Wold redefinió y Martens implementó en contextos industriales reales.\nUn aspecto técnico que gobierna este método se puede resumir así: sin compresión no hay control.\nMás adelante veremos qué significa eso, pero desde esta perspectiva, la quimiometría aplicada a procesos de transformación no solo mejora la detección temprana de desviaciones: reduce controversias. En todos los casos, el objetivo es uno solo: producir un procedimiento de control. Para que sea exitoso los datos deben ser “comprimibles”. De lo contrario, el control no es posible.\nAl fundamentar las decisiones en modelos multivariables trazables y métricas bien definidas, se eliminan interpretaciones ambiguas, discusiones subjetivas y juicios basados en observaciones parciales o aisladas. El resultado es un mecanismo de decisión que puede ser explicado, defendido y auditado.\nEn este sentido, la misión de este sitio es clara: habilitar a los usuarios de métodos multivariables para comprender estas herramientas con mayor profundidad y aplicarlas con mayor eficacia, particularmente en el control estadístico y el diagnóstico de procesos fisicoquímicos multivariables, donde la objetividad y la transparencia no son opcionales, sino requisitos operativos."
  },
  {
    "objectID": "marco_teorico.html#conclusión",
    "href": "marco_teorico.html#conclusión",
    "title": "La Relación Entre Fisicoquímica Industrial Y Estadística Multivariable",
    "section": "3 Conclusión",
    "text": "3 Conclusión\nQuien haya llegado hasta aquí con atención probablemente pertenece a uno de dos grupos:\n\nQuienes están comenzando su trayectoria profesional en la ciencia y la ingeniería de procesos fisicoquímicos, y\nQuienes, tras años de experiencia, sabían que este lenguaje existía, pero rara vez se expone con claridad operativa.\n\nPara el científico y el ingeniero joven, el mensaje es directo aunque no siempre evidente: lo importante no es “analizar datos”, sino obtener respuestas. Hacerlo correctamente exige aceptar que la variabilidad no es un error ni un estorbo, sino la única fuente legítima de información sobre la estabilidad real de un sistema fisicoquímico.\nAprender quimiometría no es aprender un conjunto de técnicas. Es adquirir una forma de pensar que permite distinguir entre ruido, estructura y riesgo operativo antes de que el problema se manifieste en el producto, en el cliente o en el mercado.\nPara el profesional senior, el valor es distinto pero igual de claro. Nada de lo aquí expuesto es novedoso en el sentido académico y, precisamente por eso, es relevante. Estas metodologías han sobrevivido décadas de escrutinio porque funcionan bajo condiciones reales: con datos imperfectos, restricciones operativas y consecuencias contractuales. Reconocerlas no es un acto de nostalgia metodológica, sino de rigor profesional: es elegir herramientas cuya trazabilidad matemática permite sostener decisiones cuando más se necesita hacerlo, sin depender de teorías académicas formuladas bajo supuestos ideales.\nEste texto no pretende convencer a quien busca atajos, resultados rápidos o modelos que “funcionen” sin ser comprendidos. Tampoco dialoga con la necesidad de novedad por sí misma, ni pretende ajustarse a preceptos deterministas que colapsan frente a la realidad estocástica de fenómenos gobernados por la entropía, que es, en última instancia, la única fuente física cuyos efectos sobre la varianza se buscan controlar.\nLa quimiometría aplicada al control de procesos que producen productos no compite por atención, novedad ni popularidad. Compite por responsabilidad, seriedad y eficacia. En entornos industriales, esa responsabilidad se mide en decisiones defendibles, procesos estables, productos conformes y dinero perdido o ganado. Observación tras observación. Lote por lote. Cliente por cliente. Todos los días.\nQuien encuentre aquí un marco útil para sus propósitos encontrará también una invitación implícita: profundizar, cuestionar con rigor, estudiar las fuentes originales y, sobre todo, aplicar estos métodos con criterio.\nQuien, por el contrario, haya llegado hasta aquí sin la intención de aprender ni crecer, pero aun así persista, difícilmente encontrará algo de valor: es evidente que está buscando otra cosa.\nEste espacio existe para quienes ya entienden (o están dispuestos a aprender) que:\n\nla calidad no se declara, se demuestra;\nlos datos no se analizan, se interrogan; y\nla estadística multivariable, bien utilizada, no es un accesorio académico, sino una herramienta de trabajo rutinaria que sirve y protege los intereses del negocio.\n\nEsta lectura está dirigida al científico industrial y al ingeniero de procesos, junior y senior, que están más interesados en resultados defendibles y procedimientos maduros (probados por la experiencia y el tiempo) que en modas académicas o nuevas promesas metodológicas que, aunque suenen atractivas, apenas están en gestación o incubación."
  },
  {
    "objectID": "index4.html",
    "href": "index4.html",
    "title": "4. Análisis de Causas-Raíz en MSPC de Datos Fisicoquímicos",
    "section": "",
    "text": "En análisis multivariable de procesos fisicoquímicos, las causas-raíz no se deducen ni se proponen: se identifican matemáticamente.\nToda observación multivariable anómala se proyecta primero sobre los grados de libertad reales del sistema, es decir, sobre sus modos propios. En ese espacio, la desviación queda expresada en términos de scores normalizados por la varianza natural capturada por los valores eigen:\n\n\ndiagonalizados en la matriz \\(\\boldsymbol{\\Lambda}\\):\n\n\n\ny posteriormente retraducidos a la dimensión material mediante los vectores propios:\n\n\n\norganizados en la matriz \\(\\boldsymbol{P}\\):\n\n\n\nEste encadenamiento (proyección, normalización por varianza y retorno al espacio físico) es una consecuencia directa del álgebra lineal aplicada a los grados de libertad efectivos del sistema, y conduce de forma natural a las contribuciones \\(\\boldsymbol{t_{cont}}\\):\n\n\n\n\n\n\nLas contribuciones t y q son la esencia del ANÁLISIS CAUSA-RAÍZ con base científica.\nTodo ocurre dentro del software, pero el beneficio es este: el vector resultante \\(\\boldsymbol{t_{cont}}\\) indicará, visulamente, cuál o cuáles fueron las variables causantes de la no conformidad detectada, en un lote o en un instante de tiempo.\nPor eso es tan valiosa. Nuestro software las ordena de forma descendente, de izquierda a derecha.\nEsta expresión no es interpretativa ni heurística. Es una definición operativa que cuantifica cómo cada variable fisicoquímica participa, de forma individual, en una desviación colectiva, a través de los modos retenidos, ponderados por sus autovalores.\nDichos autovalores, como bien sabemos, representan la varianza contenida en cada uno de los grados de libertad efectivos del sistema. Y a su vez, cada grado de libertad concentra un componente de los modos de vibración de cada variable. Por eso “descomponemos los componentes”, de su forma condensada a su forma individual. El propósito es obtener e identificar la constribución t y q. ¿Para qué? Lo que queremos es saber el origen y causa de una no conformidad multivariable. La respuesta de un problema de no conformidad viene allí.\nAsí, todo aquello que no puede ser explicado por dichos modos queda necesariamente fuera de ese subespacio. Lo que queda fuera del subespacio, por definición, es el residuo de las contribuciones \\(\\boldsymbol{q_{cont}}\\) y que emergen directamente como:\n\n\n\nAquí no existe proyección ni reescalamiento. Cada variable contribuye exactamente en la medida en que introduce información ajena al subespacio físico del proceso.\n\n\n\nComo el lector puede darse cuenta, seguirle la pista a la variación confinada en sistemas complejos con propósitos de validación y control estadístico, no es imposible, pero sí es una tarea intrincada. El autor ha hecho lo más que ha podido para traerle al lector algo de claridad, pero la labor no puede ser eshaustiva ni más detallada. Los libros de texto son para eso.\nLo que sí hemos hecho deliberadamente en este espacio, es romper con la solemnidad del estilo discursivo académico, sin sacrificar rigor matemático. El propósito es enteramente didáctico. Si este trabajo cumplió su propósito, el autor confía en que aquel lector que tenga interés en profundizar, podrá hacerlo ahora con un poco de ventaja didáctica. Si así sucede, este material habrá sido exitoso. De lo contrario, esta redacción fracasó y la culpa es totalmente del autor.\nEn cualqueir caso, el mayor valor agregado queda en la identificación legítima de causas, cuando los datos indican la presencia de anomalías antes de que sea demasiado tarde.\nEsta es la razón por la cual las contribuciones \\(\\boldsymbol{t_{cont}}\\) y \\(\\boldsymbol{q_{cont}}\\) constituyen el núcleo del diagnóstico de causas raíz en MSPC fisicoquímico. No son gráficos auxiliares ni explicaciones a posteriori: son la traducción directa de los grados de libertad capturados por el análisis eigen, pero ahora de vuelta a la realidad material del proceso de transformación.\nLo que el lector verá a continuación son cinco ejemplos de estas contribuciones aplicadas a la varianza de los lotes de vino Grignolino del conjunto de Forina, tal como deben aparecer durante el monitoreo real y la consulta técnica de datos históricos: como evidencia cuantitativa, físicamente interpretable, directamente accionable y auditable.\nLos gráficos presentados ilustran el nivel de calidad interactiva que nuestro sistema puede ofrecer a su organización durante la operación diaria y el análisis experto.\nLe invitamos a explorar los 5 ejemplos: cada uno expone las causas-raíz en forma gráfica, por orden de magnitud de contribución de izquierda a derecha, reordenando e identificando en cada caso las principales variables causantes de la no conformidad y la mayor variación.\nLas contribuciones-t se ilustran en color verde y las contribuiciones-q en color amarillo.\n\n\n\nComo es natural, estos métodos solo satisfacen a especialistas exigentes y profesionales comprometidos con el aseguramiento de la calidad.\nNuestro objetivo con toda la exposición en este sitio, ha sido que el proceso multivariable deje de ser una “nube de datos” y MSPC deje de ser una “caja negra”, para convertirse en un sistema de diagnóstico que señala, sin ambigüedad, qué variable rompió el equilibrio.\nEsperamos haberlo logrado.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "4. Contribuciones t y q"
    ]
  },
  {
    "objectID": "index4.html#de-dónde-nacen-realmente-las-contribuciones-boldsymbolt_cont-y-boldsymbolq_cont",
    "href": "index4.html#de-dónde-nacen-realmente-las-contribuciones-boldsymbolt_cont-y-boldsymbolq_cont",
    "title": "4. Análisis de Causas-Raíz en MSPC de Datos Fisicoquímicos",
    "section": "",
    "text": "En análisis multivariable de procesos fisicoquímicos, las causas-raíz no se deducen ni se proponen: se identifican matemáticamente.\nToda observación multivariable anómala se proyecta primero sobre los grados de libertad reales del sistema, es decir, sobre sus modos propios. En ese espacio, la desviación queda expresada en términos de scores normalizados por la varianza natural capturada por los valores eigen:\n\n\ndiagonalizados en la matriz \\(\\boldsymbol{\\Lambda}\\):\n\n\n\ny posteriormente retraducidos a la dimensión material mediante los vectores propios:\n\n\n\norganizados en la matriz \\(\\boldsymbol{P}\\):\n\n\n\nEste encadenamiento (proyección, normalización por varianza y retorno al espacio físico) es una consecuencia directa del álgebra lineal aplicada a los grados de libertad efectivos del sistema, y conduce de forma natural a las contribuciones \\(\\boldsymbol{t_{cont}}\\):\n\n\n\n\n\n\nLas contribuciones t y q son la esencia del ANÁLISIS CAUSA-RAÍZ con base científica.\nTodo ocurre dentro del software, pero el beneficio es este: el vector resultante \\(\\boldsymbol{t_{cont}}\\) indicará, visulamente, cuál o cuáles fueron las variables causantes de la no conformidad detectada, en un lote o en un instante de tiempo.\nPor eso es tan valiosa. Nuestro software las ordena de forma descendente, de izquierda a derecha.\nEsta expresión no es interpretativa ni heurística. Es una definición operativa que cuantifica cómo cada variable fisicoquímica participa, de forma individual, en una desviación colectiva, a través de los modos retenidos, ponderados por sus autovalores.\nDichos autovalores, como bien sabemos, representan la varianza contenida en cada uno de los grados de libertad efectivos del sistema. Y a su vez, cada grado de libertad concentra un componente de los modos de vibración de cada variable. Por eso “descomponemos los componentes”, de su forma condensada a su forma individual. El propósito es obtener e identificar la constribución t y q. ¿Para qué? Lo que queremos es saber el origen y causa de una no conformidad multivariable. La respuesta de un problema de no conformidad viene allí.\nAsí, todo aquello que no puede ser explicado por dichos modos queda necesariamente fuera de ese subespacio. Lo que queda fuera del subespacio, por definición, es el residuo de las contribuciones \\(\\boldsymbol{q_{cont}}\\) y que emergen directamente como:\n\n\n\nAquí no existe proyección ni reescalamiento. Cada variable contribuye exactamente en la medida en que introduce información ajena al subespacio físico del proceso.\n\n\n\nComo el lector puede darse cuenta, seguirle la pista a la variación confinada en sistemas complejos con propósitos de validación y control estadístico, no es imposible, pero sí es una tarea intrincada. El autor ha hecho lo más que ha podido para traerle al lector algo de claridad, pero la labor no puede ser eshaustiva ni más detallada. Los libros de texto son para eso.\nLo que sí hemos hecho deliberadamente en este espacio, es romper con la solemnidad del estilo discursivo académico, sin sacrificar rigor matemático. El propósito es enteramente didáctico. Si este trabajo cumplió su propósito, el autor confía en que aquel lector que tenga interés en profundizar, podrá hacerlo ahora con un poco de ventaja didáctica. Si así sucede, este material habrá sido exitoso. De lo contrario, esta redacción fracasó y la culpa es totalmente del autor.\nEn cualqueir caso, el mayor valor agregado queda en la identificación legítima de causas, cuando los datos indican la presencia de anomalías antes de que sea demasiado tarde.\nEsta es la razón por la cual las contribuciones \\(\\boldsymbol{t_{cont}}\\) y \\(\\boldsymbol{q_{cont}}\\) constituyen el núcleo del diagnóstico de causas raíz en MSPC fisicoquímico. No son gráficos auxiliares ni explicaciones a posteriori: son la traducción directa de los grados de libertad capturados por el análisis eigen, pero ahora de vuelta a la realidad material del proceso de transformación.\nLo que el lector verá a continuación son cinco ejemplos de estas contribuciones aplicadas a la varianza de los lotes de vino Grignolino del conjunto de Forina, tal como deben aparecer durante el monitoreo real y la consulta técnica de datos históricos: como evidencia cuantitativa, físicamente interpretable, directamente accionable y auditable.\nLos gráficos presentados ilustran el nivel de calidad interactiva que nuestro sistema puede ofrecer a su organización durante la operación diaria y el análisis experto.\nLe invitamos a explorar los 5 ejemplos: cada uno expone las causas-raíz en forma gráfica, por orden de magnitud de contribución de izquierda a derecha, reordenando e identificando en cada caso las principales variables causantes de la no conformidad y la mayor variación.\nLas contribuciones-t se ilustran en color verde y las contribuiciones-q en color amarillo.\n\n\n\nComo es natural, estos métodos solo satisfacen a especialistas exigentes y profesionales comprometidos con el aseguramiento de la calidad.\nNuestro objetivo con toda la exposición en este sitio, ha sido que el proceso multivariable deje de ser una “nube de datos” y MSPC deje de ser una “caja negra”, para convertirse en un sistema de diagnóstico que señala, sin ambigüedad, qué variable rompió el equilibrio.\nEsperamos haberlo logrado.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "4. Contribuciones t y q"
    ]
  },
  {
    "objectID": "index2.html",
    "href": "index2.html",
    "title": "¿Cómo Investigar Datos Continuos Multivariables?",
    "section": "",
    "text": "Las distribuciones de probabilidad son herramientas naturales para explorar el comportamiento de datos univariables.\nUn histograma acompañado de su curva de densidad suelen ser suficientes cuando solo hay una variable en juego.\n\n\n\n\n\n\nLos scatter plots (gráficos de dispersión), por su parte, son excelentes cuando trabajamos con dos variables continuas. Incluso pueden extenderse a tres dimensiones, aunque con claras limitaciones visuales e interpretativas.\n\n\n\n\n\n\nEl problema analítico aparece cuando el sistema no es de dos ni de tres variables, sino de muchas. Tal y como ocurre en la vida real.\n\n\nEn un scatter plot:\n\nlos ejes x e y (y z en 3D) son ortogonales\ncada gráfico solo puede mostrar una relación a la vez\n\nEsto funciona bien en baja dimensión, pero no escala cuando el proceso tiene múltiples variables correlacionadas, como ocurre en casi cualquier sistema real.\n\n\n\nPara datos continuos multivariables, una alternativa poderosa son los gráficos de coordenadas paralelas.\nEn lugar de ejes perpendiculares, todos los ejes son paralelos entre sí.\n\nCada variable tiene su propio eje vertical\nCada eje se escala normalmente entre su mínimo y máximo\nUn solo caso (una observación, una corrida, una formulación, un lote, un prototipo, una versión, una sección, un sitio, etc.) se representa como una línea poligonal que cruza todos los ejes\n\nAsí, una línea completa representa un estado del sistema completo.\nOtras líneas representan otro estado del mismo sistema.\n\n\n\nEsta idea no es nueva.\n\nJohn Hartigan ya hablaba en 1975 de profile plots, una idea esencialmente equivalente.\nAlfred Inselberg desarrolló formalmente la geometría de las coordenadas paralelas y la documentó extensamente en su libro de 2009.\nWilliam Wegman fue uno de los primeros en proponer su uso sistemático para análisis de datos.\n\nLa razón por la que estas ideas no prosperaron antes no fue conceptual, sino computacional. Hoy, con capacidad gráfica y cómputo moderno, estas visualizaciones son prácticas, interactivas y extremadamente informativas.\nHartigan llamó a estas líneas “perfiles”, y ese nombre sigue siendo muy adecuado: cada línea es la huella multivariable completa de un caso individual.\n\n\n\nUn scatter plot responde a la pregunta:\n¿Cómo se relacionan estas dos variables?\nUn gráfico de coordenadas paralelas responde a otra más potente:\n¿Cómo se comporta el sistema completo?\nCuando el objetivo no es solo observar, sino entender, comparar, diagnosticar, controlar y validar, la multivariabilidad deja de ser un problema visual o una “aplicación para casos especiales” y se convierte en lo que realmente es y para lo que fue concebida: información estructurada que explica la totalidad del proceso a partir de datos completos.\nY ahí empieza el verdadero análisis multivariable.\nHacer menos que eso significa ignorar información arbitrariamente.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "2. Diagnóstico Compuesto"
    ]
  },
  {
    "objectID": "index2.html#análisis-gráfico-de-datos-multivariables",
    "href": "index2.html#análisis-gráfico-de-datos-multivariables",
    "title": "¿Cómo Investigar Datos Continuos Multivariables?",
    "section": "",
    "text": "Las distribuciones de probabilidad son herramientas naturales para explorar el comportamiento de datos univariables.\nUn histograma acompañado de su curva de densidad suelen ser suficientes cuando solo hay una variable en juego.\n\n\n\n\n\n\nLos scatter plots (gráficos de dispersión), por su parte, son excelentes cuando trabajamos con dos variables continuas. Incluso pueden extenderse a tres dimensiones, aunque con claras limitaciones visuales e interpretativas.\n\n\n\n\n\n\nEl problema analítico aparece cuando el sistema no es de dos ni de tres variables, sino de muchas. Tal y como ocurre en la vida real.\n\n\nEn un scatter plot:\n\nlos ejes x e y (y z en 3D) son ortogonales\ncada gráfico solo puede mostrar una relación a la vez\n\nEsto funciona bien en baja dimensión, pero no escala cuando el proceso tiene múltiples variables correlacionadas, como ocurre en casi cualquier sistema real.\n\n\n\nPara datos continuos multivariables, una alternativa poderosa son los gráficos de coordenadas paralelas.\nEn lugar de ejes perpendiculares, todos los ejes son paralelos entre sí.\n\nCada variable tiene su propio eje vertical\nCada eje se escala normalmente entre su mínimo y máximo\nUn solo caso (una observación, una corrida, una formulación, un lote, un prototipo, una versión, una sección, un sitio, etc.) se representa como una línea poligonal que cruza todos los ejes\n\nAsí, una línea completa representa un estado del sistema completo.\nOtras líneas representan otro estado del mismo sistema.\n\n\n\nEsta idea no es nueva.\n\nJohn Hartigan ya hablaba en 1975 de profile plots, una idea esencialmente equivalente.\nAlfred Inselberg desarrolló formalmente la geometría de las coordenadas paralelas y la documentó extensamente en su libro de 2009.\nWilliam Wegman fue uno de los primeros en proponer su uso sistemático para análisis de datos.\n\nLa razón por la que estas ideas no prosperaron antes no fue conceptual, sino computacional. Hoy, con capacidad gráfica y cómputo moderno, estas visualizaciones son prácticas, interactivas y extremadamente informativas.\nHartigan llamó a estas líneas “perfiles”, y ese nombre sigue siendo muy adecuado: cada línea es la huella multivariable completa de un caso individual.\n\n\n\nUn scatter plot responde a la pregunta:\n¿Cómo se relacionan estas dos variables?\nUn gráfico de coordenadas paralelas responde a otra más potente:\n¿Cómo se comporta el sistema completo?\nCuando el objetivo no es solo observar, sino entender, comparar, diagnosticar, controlar y validar, la multivariabilidad deja de ser un problema visual o una “aplicación para casos especiales” y se convierte en lo que realmente es y para lo que fue concebida: información estructurada que explica la totalidad del proceso a partir de datos completos.\nY ahí empieza el verdadero análisis multivariable.\nHacer menos que eso significa ignorar información arbitrariamente.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "2. Diagnóstico Compuesto"
    ]
  },
  {
    "objectID": "index2.html#análisis-gráfico-y-estadístico-de-datos-multivariables-en-simultáneo",
    "href": "index2.html#análisis-gráfico-y-estadístico-de-datos-multivariables-en-simultáneo",
    "title": "¿Cómo Investigar Datos Continuos Multivariables?",
    "section": "2 Análisis gráfico y estadístico de datos multivariables en simultáneo",
    "text": "2 Análisis gráfico y estadístico de datos multivariables en simultáneo\nEl gráfico de la sección siguiente explora el conocido conjunto de datos multivariables de Forina, utilizado clásicamente para el estudio de la calidad y el origen de vinos italianos. En nuestro caso, nos centramos en vinos elaborados a partir de uvas Grignolino.\nHemos elegido este ejemplo por una razón particular: los procesos de fermentación integran dos mundos en uno solo: el industrial y el ambiental.\n¿A qué nos referimos?\nAl tratarse de un producto que atiende intereses comerciales, la dimensión industrial exige ejercer control sobre la calidad. Sin embargo, en el caso específico de productos fermentados, intervienen también factores naturales que escapan, al menos parcialmente, a la capacidad de control del productor. Es aquí donde aparece la dimensión natural, orgánica y ambiental, introduciendo una mayor variabilidad que no necesariamente se traduce en imperfecciones, sino más bien en variedad.\nAunque se desea cierta uniformidad en un producto que es natural y artesanal, también se esperan cambios. Después de todo, la naturaleza no es una máquina que fabrica en serie. Nos adaptamos, entonces, a esa variedad: productos que no son idénticos, pero que comparten más similitudes que diferencias. Y esas similitudes (y diferencias) pueden estudiarse, analizarse y validarse estadísticamente.\nEl propósito de este tipo de estudio es certificar el origen del vino combinando información proveniente tanto de las propiedades fisicoquímicas del producto como de las características del suelo donde fue cultivada la uva. Naturalmente, este enfoque conduce a la realización de múltiples mediciones simultáneas y, por ende, a la generación de matrices de datos extensas y altamente correlacionadas.\nDesde luego, este es solo un ejemplo representativo. Las aplicaciones reales serán tan variadas como lo sean las necesidades del cliente.\nLo que presentamos al lector en la siguiente sección es una demostración visual de cómo luce la información multivariable en la práctica: representada mediante gráficos de coordenadas paralelas, y enriquecida con los beneficios adicionales de la interactividad que la tecnología actual nos permite.\nEsta visualización se acompaña de los resultados de un análisis estadístico multivariable basado en la identificación de los grados de libertad fundamentales del sistema, los cuales se traducen en distancias estadísticas que responden únicamente a las dos preguntas que realmente importan en este contexto:\n\n¿Qué vinos sí pertenecen al grupo?\n¿Qué vinos no pertenecen al grupo?\n\nEl objetivo es demasiado simple: queremos saber cuáles son semejenates y cuáles diferentes entre sí.\nEn términos formalmente analíticos, lo que buscamos es el outlier: aquellas observaciones singulares que se apartan de los patrones que definen nuestro estándar de calibración a partir del conjunto histórico de datos (HDS). En el caso multivariable, este tipo de desviación no puede evaluarse variable por variable, sino que exige considerar simultáneamente todas las contribuciones y correlaciones del sistema.\nHemos asignado colores asociados a los tres perfiles posibles que indican el estatus de cada caso individual dentro del espacio multivariable, de acuerdo con sus respectivas distancias estadísticas.\nUna vez procesados los datos y llevados al monitor, estos resultados pueden publicarse fácilmente en línea y reportarse como análisis multivariable de información histórica o como lotes de referencia utilizados para calibración y validación.\nInvitamos al lector a hacer clic en la sección 2.1 del menú izquierdo y explorar el gráfico de coordenadas paralelas y a experimentar de primera mano cómo la complejidad multivariable puede hacerse visible, interpretable, operable y comunicable.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "2. Diagnóstico Compuesto"
    ]
  },
  {
    "objectID": "acerca.html#si-no-hay-compresión-no-hay-control.",
    "href": "acerca.html#si-no-hay-compresión-no-hay-control.",
    "title": "Acerca del Autor",
    "section": "2 “Si no hay compresión, no hay control.”",
    "text": "2 “Si no hay compresión, no hay control.”\nEn análisis multivariable de datos fisicoquímicos, esta frase acuñada por el autor lo dice todo.\nVíctor Soto Del Toro es Químico Industrial por la Universidad Autónoma de Baja California, con especialización práctica en formulación, dispersiones, emulsiones y preparaciones fisicoquímicas para aplicaciones industriales especializadas.\nHa servido en el sector público, tanto a nivel federal como estatal, en programas y proyectos de protección ambiental, incluyendo inspección industrial de residuos peligrosos, control de contaminación de aguas residuales y verificación operativa de plantas de tratamiento. Esta experiencia le permitió enfrentar, desde dentro, la brecha recurrente entre el cumplimiento documental y la evidencia técnica real.\nEs creador e inventor del producto Apest-Off, formulado a base de ricinoleato de zinc, actualmente utilizado por clientes de los sectores veterinario y funerario para el control inmediato y verificable de la calidad del aire respirable.\nSu otra pasión (inseparable de la primera) es la claridad en el rigor analítico aplicado a la rendición de cuentas técnicas. Este sitio es una manifestación directa de esa convicción.\nLa programación estadística en el lenguaje R le ha permitido colaborar en proyectos y desarrollar aplicaciones analíticas para clientes que necesitan comprobar y demostrar, de forma defendible y auditable, que sus mediciones, resultados y decisiones están validados bajo estadística inferencial formal.\nEl Q.I. Víctor Soto sostiene una convicción central:\nLa estocástica clásica es la cámara fotográfica que retrata la entropía en un instante.\nLa quimiometría la filma de inicio a fin.\nEl analista de datos no es más que un fotógrafo.\nEl científico y el ingeniero, en cambio, son directores de escena.\nLa calidad de la imagen depende directamente de su dominio técnico.\nSin método, sin criterio y sin rigor, la imagen será inevitablemente borrosa y deficiente.\nTodo científico e ingeniero serio que aspire a ejercer su profesión con responsabilidad tiene acceso al control cuantitativo que las ciencias exactas exigen. No requiere intuición extraordinaria ni talento excepcional: requiere medir la variación, cuantificarla y vigilarla, porque la calidad de su trabajo en beneficio de los demás, reside precisamente allí.\nY en procesos fisicoquímicos multivariables eso solo significa una cosa: sin compresión no hay control.\nSi los datos comprimen el control del proceso es totalmente posible.\nUn cliente no merece menos que eso.\n________________________________________________________________________\nVíctor vive en Tijuana con su esposa y sus dos hijos.\nLo que más ama de su comunidad es la deliciosa comida.\n________________________________________________________________________\nContacto"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análisis Multivariable para Procedimientos de Control Estadístico de Procesos Fisicoquímicos",
    "section": "",
    "text": "Los procesos fisicoquímicos son, por naturaleza, multivariables.\nPara el lector que busca comprender qué es realmente el análisis multivariable aplicado al proceso industrial, es necesario considerar antes algo mucho más fundamental.\nUn fenómeno multivariable no vive en las variables.\nVive en la estructura de covarianza que las conecta.\nEsto puede sonar extraño al inicio, pero la realidad (y por tanto el control) de un proceso multivariable no reside en las variables individuales, sino en el subespacio que estas conforman.\nEse subespacio es un lugar físico e intelectual al mismo tiempo.\nNo se observa directamente con los ojos, sino que se reconstruye con la mente y con matemáticas. Las variables fisicoquímicas, cuando se capturan como datos, no son el fenómeno en sí: son manifestaciones parciales de una expresión más esencial, una estructura que filtra la confusión para revelar significado.\nEse significado solo puede encontrarse en el subespacio que contiene la expresión mínima y fundamental del objeto central que es el que en realidad se analiza y el que más interesa, porque es el que está en el fondo del asunto: el grado de libertad.\nUn grado de libertad hace tres cosas esenciales:\n\nContiene la variación natural del proceso\nLa separa en componentes independientes\nNos muestra cómo se comporta el sistema\n\nUn proceso real no tiene un solo grado de libertad.\nEl subespacio contiene varios. Algunos son indispensables; otros, irrelevantes. La diferencia es crucial: los principales contienen la información esencial para comprender, diagnosticar y decidir; el resto es redundancia o ruido.\nEse subespacio tiene nombre.\nTiene valores.\nY tiene vectores.\nEs el subespacio eigen.\nEl análisis multivariable con base científica aplicado a procesos industriales comienza formalmente ahí.\nY de eso es exactamente de lo que hablaremos en este sitio.\nLe damos la bienvenida.\n\n\nEl control estadístico multivariable (MSPC) difiere del control univariable tradicional (SPC).\nNo es “mejor” ni “peor”; es conceptualmente distinto y responde a una lógica diferente.\n\n\n\nUn procedimiento de control univariable puede compararse con un detector de humo:\nindica que el fuego existe, pero lo hace después de que la ignición ya ocurrió.\nUn procedimiento de control multivariable es más parecido a un detector infrarrojo de temperatura:\ndetecta incrementos simultáneos en distintos puntos antes de que se alcance el punto de ignición.\nAmbos enfoques son útiles.\nLa diferencia es que el segundo detecta cambios y tendencias más rápido porque contiene y procesa mucha más información. ¿Cómo?\nAnaliza las interacciones internas a partir de la covarianza del sistema, mientras que el primero las ignora. Nunca las toca.\nPor ello, el análisis multivariable es más sensible e informativo, especialmente para procesos fisicoquímicos complejos.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "1. Inicio"
    ]
  },
  {
    "objectID": "index.html#cómo-por-qué-para-qué-y-de-dónde-surge-el-análisis-multivariable",
    "href": "index.html#cómo-por-qué-para-qué-y-de-dónde-surge-el-análisis-multivariable",
    "title": "Análisis Multivariable para Procedimientos de Control Estadístico de Procesos Fisicoquímicos",
    "section": "",
    "text": "Los procesos fisicoquímicos son, por naturaleza, multivariables.\nPara el lector que busca comprender qué es realmente el análisis multivariable aplicado al proceso industrial, es necesario considerar antes algo mucho más fundamental.\nUn fenómeno multivariable no vive en las variables.\nVive en la estructura de covarianza que las conecta.\nEsto puede sonar extraño al inicio, pero la realidad (y por tanto el control) de un proceso multivariable no reside en las variables individuales, sino en el subespacio que estas conforman.\nEse subespacio es un lugar físico e intelectual al mismo tiempo.\nNo se observa directamente con los ojos, sino que se reconstruye con la mente y con matemáticas. Las variables fisicoquímicas, cuando se capturan como datos, no son el fenómeno en sí: son manifestaciones parciales de una expresión más esencial, una estructura que filtra la confusión para revelar significado.\nEse significado solo puede encontrarse en el subespacio que contiene la expresión mínima y fundamental del objeto central que es el que en realidad se analiza y el que más interesa, porque es el que está en el fondo del asunto: el grado de libertad.\nUn grado de libertad hace tres cosas esenciales:\n\nContiene la variación natural del proceso\nLa separa en componentes independientes\nNos muestra cómo se comporta el sistema\n\nUn proceso real no tiene un solo grado de libertad.\nEl subespacio contiene varios. Algunos son indispensables; otros, irrelevantes. La diferencia es crucial: los principales contienen la información esencial para comprender, diagnosticar y decidir; el resto es redundancia o ruido.\nEse subespacio tiene nombre.\nTiene valores.\nY tiene vectores.\nEs el subespacio eigen.\nEl análisis multivariable con base científica aplicado a procesos industriales comienza formalmente ahí.\nY de eso es exactamente de lo que hablaremos en este sitio.\nLe damos la bienvenida.\n\n\nEl control estadístico multivariable (MSPC) difiere del control univariable tradicional (SPC).\nNo es “mejor” ni “peor”; es conceptualmente distinto y responde a una lógica diferente.\n\n\n\nUn procedimiento de control univariable puede compararse con un detector de humo:\nindica que el fuego existe, pero lo hace después de que la ignición ya ocurrió.\nUn procedimiento de control multivariable es más parecido a un detector infrarrojo de temperatura:\ndetecta incrementos simultáneos en distintos puntos antes de que se alcance el punto de ignición.\nAmbos enfoques son útiles.\nLa diferencia es que el segundo detecta cambios y tendencias más rápido porque contiene y procesa mucha más información. ¿Cómo?\nAnaliza las interacciones internas a partir de la covarianza del sistema, mientras que el primero las ignora. Nunca las toca.\nPor ello, el análisis multivariable es más sensible e informativo, especialmente para procesos fisicoquímicos complejos.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "1. Inicio"
    ]
  },
  {
    "objectID": "index.html#fluctuación-estructura-y-control",
    "href": "index.html#fluctuación-estructura-y-control",
    "title": "Análisis Multivariable para Procedimientos de Control Estadístico de Procesos Fisicoquímicos",
    "section": "2 Fluctuación, estructura y control",
    "text": "2 Fluctuación, estructura y control\nLos datos multivariables siempre exhiben fluctuaciones interconectadas.\nPara construir procedimientos de control estadísticamente legítimos, existe una sola pregunta analítica con validez científica:\n¿Esas fluctuaciones están estructuradas en grados de libertad dominantes, o son esencialmente ruido?\nLa respuesta la proporciona el análisis eigen.\nY la base es el álgebra lineal. Todo el análisis y la tecnología para extraer las respuestas están ahí.\nLo siguiente que veremos puede sonar “teórico” pero en realidad, es la base fundamental del análisis de datos y depende de la identificación de los grados de libertad de un sistema multivariable que pudiese o no contener información.\nCada grado de libertad queda descrito como un valor eigen \\(\\lambda_i\\) que cuantifica la varianza asociada a su respectivo grado de libertad independiente del sistema, mientras que los vectores eigen correspondientes definen las direcciones ortogonales de fluctuación en el espacio de las variables originales.\nLas expresiones formales que definen y explican estos conceptos adquieren la forma del álgebra lineal y todo comienza con la matriz de nuestros de datos de proceso, \\(\\boldsymbol{X}\\) y su respectiva matriz de covarianza \\(\\boldsymbol{\\Sigma}\\), descompuesta en sus vectores eigen \\(\\boldsymbol{P}\\) y sus grados de libertad \\(\\boldsymbol{\\Lambda}\\).\n\n\\[\\boldsymbol{\\Sigma} = \\mathbf{P}\\boldsymbol{\\Lambda}\\mathbf{P}^\\top\\]\nDigamos que \\(\\mathbf{X} \\in \\mathbb{R}^{n \\times m}\\) es nuestra matriz de datos multivariables de calibración en Fase I, centrada y escalada.\nLuego, tenemos su matriz de covarianzas:\n\n\n\\[\\boldsymbol{\\Sigma} = \\frac{1}{n-1}\\mathbf{X}^\\top \\mathbf{X}\\]\nPor eso el análisis eigen consiste simplemente en resolver la ecuación característica:\n\n\n\\[\\det(\\boldsymbol{\\Sigma} - \\lambda \\mathbf{I}) = 0\\]\nLa física clásica nos enseñó que esta determinante nos entrega las raíces \\(\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_p\\) que definen la cantidad y magnitud de cada uno de los modos elementales de fluctuación material de nuestro proceso, siempre y cuando se encuentre en el equilibrio. Esto es simple de entender porque se supone que esa es la condición de nuestro proceso cuando está bajo control y el producto es conforme.\nEn términos prácticos: podremos tener 5, 50 o 500 variables o más en nuestro proceso, (inclusive autocorrelacionadas en el tiempo) pero si la información está intercorrelacionada, o si fuera redundante o multicolineal, no tendremos que descartar nada porque con solo un puñado de modos elementales obtendremos toda la información que necesitamos para establecer el control estadístico del proceso con la mayor sensibilidad posible.\nEsto es justo lo que nos revela la distribución de todas las variaciones: el 100% de toda la fluctuación está repartida entre cada uno de los grados de libertad.\n¿Cómo procedemos?",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "1. Inicio"
    ]
  },
  {
    "objectID": "index.html#dos-caminos-posibles",
    "href": "index.html#dos-caminos-posibles",
    "title": "Análisis Multivariable para Procedimientos de Control Estadístico de Procesos Fisicoquímicos",
    "section": "3 Dos caminos posibles",
    "text": "3 Dos caminos posibles\nEl resultado del análisis eigen permite decidir entre dos enfoques claramente diferenciados:\n\n3.1 1. Metodologías trazables y validables\nLo primero es la proyección de una observación \\(\\mathbf{x}\\) sobre el subespacio definido por los modos dominantes. Al proyectar nuestras variables originales al subespacio ocupado por los grados de libertad, aparece la definición de una distancia estadística cuadrática conocida popularmente como Mahalanobis:\n\n\\[T^2 = \\mathbf{x}^\\top \\boldsymbol{\\Sigma}^{-1} \\mathbf{x}\\]\nTambién se representa con la letra D y en algunos textos de quimiometría se escribe como h0. Es un escalar muy popular.\nEste tipo de escalar nos permite medir la desviación global del sistema respecto a su estado de equilibrio, ubicado en el centro de la distribución de probabilidad, pero que ahora es multivariable y con forma elíptica (en el contexto univariable es la clásica curva gaussiana). Es el mismo origen en el espacio euclidiano multidimensional, pero que al escalarlo y maniobrar con la rotación de los ejes, tansitamos al espacio donde encontramos a los grados de libertad que caracterizan a nuestro sistema y ahí es donde fluctúan con independencia. El sistema no cambió. Lo único que cambió fue nuestro ángulo de observación. Y toda la información de fluctuación se conserva. Nada se pierde. Pero todo se simplifica.\nPor eso el desarrollo de metodologías estocásticas multivariables para control de procesos fisicoquímicos se fundamentan en:\n\ndistancias estadísticas,\nregiones de probabilidad con límites naturales,\npruebas de hipótesis falsables,\ncontrol explícito del error tipo I.\n\nEste enfoque es compatible con control estadístico multivariable de procesos y validación científica formal porque toda su matemática es transparente y auditable.\n\n\n\n3.2 2. Modelado algorítmico sin trazabilidad\nLo segundo es recurrir a algoritmos de machine learning para modelar patrones locales de la fluctuación, pero sin ninguna garantía de trazabilidad matemática ni validación estadística formal. El aprendizaje de máquina no constituye una metodologóia de validación porque para efectos de trazabilidad, es una “caja negra”.\nAmbos caminos son legítimos, pero no persiguen el mismo objetivo.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "1. Inicio"
    ]
  },
  {
    "objectID": "index.html#madurez-del-proceso-y-validez-estadística",
    "href": "index.html#madurez-del-proceso-y-validez-estadística",
    "title": "Análisis Multivariable para Procedimientos de Control Estadístico de Procesos Fisicoquímicos",
    "section": "4 Madurez del proceso y validez estadística",
    "text": "4 Madurez del proceso y validez estadística\nBajo condiciones de normalidad multivariable y estabilidad del proceso, el estadístico \\(T^2\\) sigue una distribución conocida, lo que permite establecer regiones elípticas de probabilidad y formular pruebas de hipótesis falsables para el control del error tipo I.\n\n\\[H_0: T^2 \\le T^2_{\\text{crit}} \\qquad H_1: T^2 &gt; T^2_{\\text{crit}}\\]\nEste procedimiento exige visualizar la normalidad multivariable en la forma de su distribución de probabilidad que emerge de manera natural: la elipse (o elipsoide).\nHaz clic sobre la siguiente imagen, rótala , muévela, haz scroll y acércate y aléjate y explora.\n\n\nwgl \n  1 \n\n\n\n\n\n\nCada punto es una observación en una tabla de datos multivariables, pero nuestro procedimiento colapsa todos los datos en puntos que se ubican en coordenadas que obedecen a los grados de libertad eigen dominantes. Cada grado de libertad eigen representa conjuntos de variables.\nLa superficie translúcida representa la región de probabilidad del 95% asociada al estadístico T².\nPor eso todos los puntos que están dentro de la elipse son observaciones conformes y las que están fuera de ella son no conformidades en la región \\(\\alpha = 0.05\\).\nLa idea es equivalente a un gráfico de control univariable. Es solo que en este formato y con esta metodología, cada punto puede contener docenas o cientos de variables, todas condensadas en un punto en el espacio.\nLa elipse no es una elección gráfica: es la manifestación directa de la estructura espectral de la matriz de covarianzas. Sin modos eigen dominantes, esta región no existe.\nPor eso, si el cliente requiere la primera vía (validación científica de sus datos multivariables), pero el análisis eigen revela ausencia de modos dominantes, ello indica que:\n\nel proceso aún no ha alcanzado la madurez y estabilidad necesarias, y\nno existen grados de libertad mínimos suficientes para una validación estadística legítima.\n\nPretender control estadístico multivariable bajo condiciones no estructuradas no es válido.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "1. Inicio"
    ]
  },
  {
    "objectID": "index.html#qué-se-busca-confirmar",
    "href": "index.html#qué-se-busca-confirmar",
    "title": "Análisis Multivariable para Procedimientos de Control Estadístico de Procesos Fisicoquímicos",
    "section": "5 ¿Qué se busca confirmar?",
    "text": "5 ¿Qué se busca confirmar?\nSi su objetivo es implementar un procedimiento de control multivariable fundamentado en la física del sistema, es indispensable confirmar:\n\nSi existen grados de libertad dominantes, y\nSi existen en cantidad mínima aceptable.\n\n\n5.1 ¿Por qué?\nPorque:\nSin grados de libertad dominantes, el control estadístico multivariable no es ni física ni matemáticamente posible.\nY sin control estadístico multivariable a partir de un proceo maduro y estable, no existe validación falsable del error tipo I.\nSi los datos carecen de estructura espectral dominante, la única alternativa razonable es modelar la fluctuación localmente, mediante algoritmos de machine learning. La búsqueda de algoritmos útiles es laboriosa y toma tiempo porque requiere comparaciones empíricas, a prueba y error bajo criterios arbitrarios o en el mejor de los casos, de validaciones cruzadas, hasta encontrar alguno que pudiera modelar el ruido generalizado. En todos los casos, la selección final depende no solo de las pruebas, sino del criterio subjetivo del analista. Por eso las metodologías con algoritmos de machine learning difícilmente son reproducibles.\nNaturalmente, la seria desventaja es que en estos casos no es posible ni factible establecer procedimientos de control a partir de validación estadística.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "1. Inicio"
    ]
  },
  {
    "objectID": "index.html#beneficio-para-el-cliente",
    "href": "index.html#beneficio-para-el-cliente",
    "title": "Análisis Multivariable para Procedimientos de Control Estadístico de Procesos Fisicoquímicos",
    "section": "6 Beneficio para el cliente",
    "text": "6 Beneficio para el cliente\nCuando los datos fisicoquímicos multivariables sí revelan estructura interna, el beneficio es doble:\n\nEs posible implementar control estadístico multivariable de alta sensibilidad.\nSe habilita la identificación de causas raíz.\n\n¿Por qué?\nPorque la señal multivariable está compuesta por señales univariables interconectadas.\nCuando se detecta una desviación multivariable, al menos una o dos variables son responsables.\nAsí, aunque sean docenas o incluso cientos, la descomposición quimiométrica de la señal permite identificarlas y cuantificarlas. Una por una. Con un clic.\nPor eso el desarrollo de metodologías por estadística multivariable a partir de la descomposición espectral eigen para identificación de grados de libertad no solo es reproducible, sino trazable.\nPor eso es científica.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "1. Inicio"
    ]
  },
  {
    "objectID": "index.html#nuestra-labor",
    "href": "index.html#nuestra-labor",
    "title": "Análisis Multivariable para Procedimientos de Control Estadístico de Procesos Fisicoquímicos",
    "section": "7 Nuestra labor",
    "text": "7 Nuestra labor\nNuestra labor es simple y fundamental:\nDeterminar si un proceso fisicoquímico es maduro, estable y estadísticamente validable.\n¿Cómo lo hacemos?\nIdentificando los modos elementales de fluctuación que emergen a partir del análisis eigen de sus datos fisicoquímicos multivariables.\nEl objetivo final es contar con un procedimiento de control que permita detectar desviaciones tempranas y en cuestión de segundos, conocer las causas.\nTodo inicia con el análisis eigen que identifica los grados de libertad en sus datos.\nY todo termina con el diagnóstico de causas-raíz. Con solo un clic.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "1. Inicio"
    ]
  },
  {
    "objectID": "index3.html",
    "href": "index3.html",
    "title": "3. Introducción al Análisis Multivariable para MSPC de Datos Fisicoquímicos",
    "section": "",
    "text": "Lo que el lector está a punto de explorar no es Control Estadístico de Procesos (SPC) tradicional.\nAunque el objetivo general permanece (vigilar, comprender y controlar un proceso), el Monitoreo y Control Estadístico Multivariable de Procesos (MSPC) responde a una realidad distinta: los procesos fisicoquímicos reales no son univariables, ni independientes, ni operativamente lineales, como el SPC clásico presupone.\nEn sistemas industriales y ambientales reales, las variables están acopladas. Comparten fuentes de variabilidad, se compensan mutuamente y evolucionan como un conjunto. Tratar cada variable por separado no es una simplificación técnica inocente: es una renuncia explícita a la estructura informacional del sistema. Y eso tiene consecuencias operativas, diagnósticas y económicas.\nEn este contexto, el uso exclusivo de la desviación estándar univariable, \\(\\sigma\\), deja de ser suficiente.\nEl objeto matemático correcto pasa a ser: \\(\\boldsymbol{\\Sigma}\\), la matriz de covarianzas, que describe cómo el sistema completo fluctúa, se organiza y mantiene coherencia estadística.\nY así tenemos:",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q"
    ]
  },
  {
    "objectID": "index3.html#antes-de-comenzar-por-qué-el-control-multivariable-es-inevitable",
    "href": "index3.html#antes-de-comenzar-por-qué-el-control-multivariable-es-inevitable",
    "title": "3. Introducción al Análisis Multivariable para MSPC de Datos Fisicoquímicos",
    "section": "",
    "text": "Lo que el lector está a punto de explorar no es Control Estadístico de Procesos (SPC) tradicional.\nAunque el objetivo general permanece (vigilar, comprender y controlar un proceso), el Monitoreo y Control Estadístico Multivariable de Procesos (MSPC) responde a una realidad distinta: los procesos fisicoquímicos reales no son univariables, ni independientes, ni operativamente lineales, como el SPC clásico presupone.\nEn sistemas industriales y ambientales reales, las variables están acopladas. Comparten fuentes de variabilidad, se compensan mutuamente y evolucionan como un conjunto. Tratar cada variable por separado no es una simplificación técnica inocente: es una renuncia explícita a la estructura informacional del sistema. Y eso tiene consecuencias operativas, diagnósticas y económicas.\nEn este contexto, el uso exclusivo de la desviación estándar univariable, \\(\\sigma\\), deja de ser suficiente.\nEl objeto matemático correcto pasa a ser: \\(\\boldsymbol{\\Sigma}\\), la matriz de covarianzas, que describe cómo el sistema completo fluctúa, se organiza y mantiene coherencia estadística.\nY así tenemos:",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q"
    ]
  },
  {
    "objectID": "index3.html#spc-varianzas-aisladas",
    "href": "index3.html#spc-varianzas-aisladas",
    "title": "3. Introducción al Análisis Multivariable para MSPC de Datos Fisicoquímicos",
    "section": "2 SPC: varianzas aisladas",
    "text": "2 SPC: varianzas aisladas\nEn SPC clásico, cada variable del proceso se analiza por separado. Su variabilidad se describe de manera independiente mediante varianzas univariables:\n\n2.1 \\[\\boldsymbol{\\sigma^2_1, \\; \\sigma^2_2, \\; \\sigma^2_3, \\;  ..., \\;  \\sigma^2_m}\n\\]\nCada \\(\\sigma_i^2\\)​ existe de forma aislada. Bajo esta formulación, las relaciones entre variables simplemente no forman parte del modelo ni del procedimiento de control.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q"
    ]
  },
  {
    "objectID": "index3.html#mspc-estructura-multivariable",
    "href": "index3.html#mspc-estructura-multivariable",
    "title": "3. Introducción al Análisis Multivariable para MSPC de Datos Fisicoquímicos",
    "section": "3 MSPC: estructura multivariable",
    "text": "3 MSPC: estructura multivariable\nEn MSPC, esta visión deja de ser suficiente.\nLas observaciones del proceso se organizan primero en una matriz de datos:\n\n3.1 \\[\n\\boldsymbol{X} =\n\\begin{bmatrix}\nx_{11} & x_{12}  & \\cdots & x_{1m} \\\\\nx_{21} & x_{22}  & \\cdots & x_{2m} \\\\\n\\vdots &  \\vdots & \\ddots & \\vdots \\\\\nx_{n1} & x_{n2}  & \\cdots & x_{nm}\n\\end{bmatrix}\n\\]\nCada fila representa un lote o un instante temporal del proceso; cada columna, una variable fisicoquímica.\n(Si los datos son secuenciales en el tiempo, el paso previo es el desdoblamiento; en ese caso se parte de un tensor. El análisis eigen posterior es el mismo.)",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q"
    ]
  },
  {
    "objectID": "index3.html#el-objeto-central-la-matriz-de-covarianzas",
    "href": "index3.html#el-objeto-central-la-matriz-de-covarianzas",
    "title": "3. Introducción al Análisis Multivariable para MSPC de Datos Fisicoquímicos",
    "section": "4 El objeto central: la matriz de covarianzas",
    "text": "4 El objeto central: la matriz de covarianzas\nA partir de la matriz de datos emerge el objeto central del MSPC:\n\n4.1 \\[\n\\boldsymbol{\\Sigma} =\n\\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12}  & \\cdots & \\sigma_{1m} \\\\\n\\sigma_{21} & \\sigma_{22}  & \\cdots & \\sigma_{2m} \\\\\n\\vdots &  \\vdots & \\ddots & \\vdots \\\\\n\\sigma_{n1} & \\sigma_{n2}  & \\cdots & \\sigma_{nm}\n\\end{bmatrix}\n\\]\nLa matriz de covarianzas contiene todas las varianzas individuales y todas las covarianzas cruzadas del sistema.\nAquí ocurre el cambio conceptual clave:\n\nSPC trabaja únicamente con varianzas.\nMSPC trabaja con varianzas y covarianzas simultáneamente.\n\nEste hecho impone un requisito metodológico no negociable: el marco matemático correcto es el álgebra lineal.\nPor ello, la calidad de la información diagnóstica que ofrecen SPC y MSPC no es comparable.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q"
    ]
  },
  {
    "objectID": "index3.html#t²-y-q-surgen-de-σ",
    "href": "index3.html#t²-y-q-surgen-de-σ",
    "title": "3. Introducción al Análisis Multivariable para MSPC de Datos Fisicoquímicos",
    "section": "5 T² y Q surgen de Σ",
    "text": "5 T² y Q surgen de Σ\nDe la matriz \\(\\boldsymbol{\\Sigma}\\) surgen de forma natural las distancias multivariables \\(T^2\\) y \\(Q\\), y es con ellas que se construyen límites de control estadísticamente válidos.\nEsto no es una preferencia metodológica.\nEs una consecuencia directa de la naturaleza física, química y matemática del proceso.\nPor esta razón:\n\nNo existen límites ±1σ, ±2σ o ±3σ en MSPC.\nNo se evalúan variables de forma aislada.\nSe analizan distancias estadísticas, subespacios latentes y consistencia estructural.\n\nLos límites no son empíricos ni heurísticos ni ideológicos: se derivan de distribuciones estadísticas bien definidas bajo supuestos explícitos.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q"
    ]
  },
  {
    "objectID": "index3.html#profesionalismo-técnico",
    "href": "index3.html#profesionalismo-técnico",
    "title": "3. Introducción al Análisis Multivariable para MSPC de Datos Fisicoquímicos",
    "section": "6 Profesionalismo técnico",
    "text": "6 Profesionalismo técnico\nEl profesional que adopta MSPC no está “complicando” el control estadístico.\nEstá asumiendo su responsabilidad técnica frente a procesos que ya no admiten aproximaciones parciales.\nLa diferencia no es académica.\nEs operativa, diagnóstica y económica.\nSi el proceso es multivariable pero el método no lo es, el control será inevitablemente incompleto. En ese escenario, la organización opera con información parcial y queda expuesta a pérdidas sistemáticas, muchas veces invisibles hasta que ya son irreversibles.\nLa materia, la energía y los procesos de transformación no se comportan como listas de variables independientes. Insistir en controlarlos así conduce, tarde o temprano, a diagnósticos incompletos, acciones correctivas afortunadas y una falsa sensación de control.\nPor eso, adoptar MSPC no es un acto de sofisticación intelectual o vanidad personal.\nEs un acto de madurez profesional, emancipación técnica y mejora continua auténtica.\nEn última instancia, asumir que una sola variable fisicoquímica (aislada, incomunicada y desconectada del resto del sistema) sea capaz de explicar el comportamiento de un proceso complejo no es una posición técnicamente defendible.\nEn el mejor de los casos, esta postura es sencillamente insuficiente.\nEn el peor, es ingenua.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q"
    ]
  },
  {
    "objectID": "introduccion.html",
    "href": "introduccion.html",
    "title": "Los Procesos Fisicoquímicos Industriales y el Análisis Multivariable",
    "section": "",
    "text": "La producción industrial sostiene prácticamente todo lo que define el confort y el bienestar de la vida moderna. Materiales, energía, medicamentos, alimentos e infraestructura existen gracias a procesos fisicoquímicos de transformación cuidadosamente diseñados. Sin embargo, formular un producto en I+D o diseñar un proceso piloto no constituye el verdadero reto. Eso apenas marca el inicio.\nEl desafío real comienza cuando el proceso entra en operación y debe producir, todos los días, un producto correcto, seguro, a tiempo y dentro de presupuesto. En ese punto, la prioridad deja de ser el diseño y pasa a ser el control.\nEn el centro de este problema se encuentra el cliente: su seguridad, su satisfacción y la obligación ética e industrial de cumplir (e idealmente superar) sus expectativas. La pregunta inevitable es:\n¿Cómo sabemos, con evidencia material, que el proceso realmente está bajo control y no solo “cumple en el papel”?\nDurante décadas, la respuesta dominante fue la cultura de la calidad y la mejora continua. Pero la calidad de un producto procesado no se sostiene en discursos ni reuniones, ni mediante herramientas estadísticas elementales o diagramas simplificados diseñados para procesos simples. Los procesos industriales de transformación fisicoquímica no son simples.\nSon sistemas altamente complejos: presentan alta variabilidad, multicolinealidad y autocorrelación. En ellos interactúan simultáneamente temperatura, energía, tiempo, concentraciones químicas, orden y estado de agregación, mezclado, transferencia de masa y transferencia de calor. No es raro que un solo proceso involucre cientos de variables que cambian juntas y de manera estructurada. En este contexto, los supuestos fundamentales de la estadística univariable clásica se rompen. Controlar variables aisladas deja de ser útil y, más aún, se vuelve conceptualmente incorrecto.\nPrecisamente por esta razón surge el control estadístico multivariable de procesos de transformación fisicoquímica. No como una sofisticación académica, sino como una respuesta directa a una necesidad industrial concreta: monitorear no solo variables, sino las relaciones entre ellas. En química y ciencias de procesos, este enfoque se consolidó bajo el nombre de quimiometría.\nEl procedimiento estándar en este campo se fundamenta en el Análisis de Componentes Principales (PCA), adaptado y validado a lo largo de décadas de trabajo científico e industrial (Wold, Martens, Jackson, MacGregor, Kourti, entre otros). A partir de PCA optimizado para datos fisicoquímicos surgen métricas clave como la T² de Hotelling (en su formulación para componentes principales) y la Q de Jackson, junto con sus respectivas contribuciones a la varianza: t y q.\nEstas métricas permiten algo fundamental:\n\nEvaluar el estado global del proceso de manera estadísticamente válida, y\nIdentificar causas raíz específicas, cuantificando su magnitud e impacto, en tiempo real.\n\nLa T² y la Q no son cajas negras ni artificios matemáticos. Son escalares que condensan el comportamiento conjunto de grupos de variables correlacionadas en una sola observación multivariable. Sus contribuciones transforman esos números en señales fisicoquímicas interpretables, directamente accionables por quien opera el proceso.\nA diferencia de muchos algoritmos de machine learning, que priorizan la predicción sacrificando interpretabilidad, estas métricas están ancladas en un marco científico trazable, validable y explicable. Por ello, en procesos fisicoquímicos industriales, la comprensión del proceso y la validación estadística no son opcionales.\nLa T² de Hotelling y la Q de Jackson encuentran hoy a algunos de sus principales detractores entre los enfoques modernistas de la inteligencia artificial y los algoritmos derivados del machine learning, cuyos promotores suelen presentarlos como la única alternativa viable para el diagnóstico industrial multivariable. Si bien estos métodos pueden aportar valor en tareas específicas (particularmente en predicción y pronóstico), todos comparten una carencia crítica en el contexto del control de procesos fisicoquímicos.\nCarecen de aquello que el ingeniero químico necesita con mayor urgencia en planta: la interpretación directa y cuantificable de la variación interna del sistema para identificar causas raíz en observaciones multivariables fuera de control.\nEsto no es una limitación circunstancial ni un problema de implementación; es una consecuencia directa de su naturaleza. Los algoritmos de machine learning operan como cajas negras: optimizan funciones objetivo sin preservar una relación explícita y trazable entre las variables originales y la desviación observada. En consecuencia, cuando el proceso se desvía, el modelo puede señalar que algo ocurrió, pero no por qué ocurrió ni qué variable física o química fue responsable.\nLas contribuciones t y q sí pueden hacerlo, porque no son heurísticas ni aproximaciones empíricas. Son un producto directo de la quimiometría, diseñadas explícitamente para descomponer la variación multivariable en términos físicamente interpretables. Existen precisamente para atender necesidades de diagnóstico en sistemas fisicoquímicos reales y forman parte del marco conceptual de la química aplicada y la ingeniería de procesos.\nEsta diferencia explica por qué muchos desarrolladores de algoritmos de machine learning pasan por alto este aspecto: T², Q, t y q son estadísticos quimiométricos que no pertenecen al dominio de las tecnologías de la información. El diagnóstico de causas raíz en procesos fisicoquímicos no es un problema genérico de datos; es un problema químico, energético y termodinámico expresado estadísticamente con métricas especializadas. Para ese problema, las contribuciones t y q siguen siendo, hoy por hoy, herramientas insustituibles.\nEl desarrollo de productos comienza con la formulación (Abbott), orientada a generar pruebas de concepto, y con el Diseño de Experimentos (Box), cuyo objetivo es producir prototipos robustos. Sin embargo, una vez que el proceso entra en operación, el problema cambia radicalmente. El desafío ya no es diseñar, sino controlar, y el control exige calibraciones multivariables continuas.\nOmitir estas calibraciones no simplifica el aseguramiento de la calidad; lo invalida. Ignorar la información estadística contenida en las correlaciones y covarianzas equivale a reducir la ciencia del proceso a empirismo y azar. No es una omisión menor ni una preferencia metodológica: es una falla técnica con consecuencias directas sobre la calidad, la seguridad y la reproducibilidad del producto.\nAunque la experiencia operativa y la intuición del ingeniero son activos valiosos, no pueden ni deben constituir el fundamento del control. Carecen de formalidad metodológica y no son transferibles ni auditables. En una cultura industrial basada en estándares, el desempeño y la estabilidad de un proceso no deben depender del talento individual, sino de metodologías científicas explícitas, reproducibles, documentadas y estadísticamente validadas.\nEsto plantea un dilema claro:\n¿Uniformamos criterios y transparentamos procedimientos?\n¿O aceptamos la opacidad, la heurística y el criterio subjetivo?\nSolo una opción es ética y estratégica al mismo tiempo.\nPor esta razón, en toda industria seria y vanguardista, el control estadístico multivariable no es una herramienta opcional ni una curiosidad académica: es un requisito profesional para todo ingeniero responsable de operar procesos fisicoquímicos complejos.\nDurante años, su adopción fue limitada no por falta de ciencia, sino por falta de medios. Hoy, esas barreras han desaparecido. El software existe, el cómputo es accesible y las herramientas están disponibles para cualquier operación industrial que se tome en serio su responsabilidad.\nEste trabajo nace de enfrentar estos problemas en contextos reales de producción industrial. No busca formar teóricos ni académicos, sino habilitar practicantes capaces de aplicar control estadístico multivariable con rigor matemático y criterio ingenieril. La buena noticia es simple: el ingeniero no necesita calcular nada. El software se encarga de la matemática; el ingeniero se concentra en entender el proceso y tomar decisiones correctas.\nEn procesos fisicoquímicos complejos, sin T² de Hotelling, sin Q de Jackson y sin contribuciones t y q, no existe un diagnóstico científico serio de causas raíz. Solo hay especulación, heurística y opinión. Eso no es una alternativa técnica aceptable.\nCon estas herramientas, el proceso deja de ser opaco y se vuelve transparente. Empieza a hablar con datos duros y gráficos claros.\nEn minutos.\nLe damos la bienvenida.\nSi estas ideas le resultan nuevas, este sitio lo pondrá al día con rapidez y le promete una sola cosa:\nMostrarle y demostrarle, con la mayor claridad posible, por qué el método Hotelling–Jackson–MacGregor es la opción por defecto para el control y diagnóstico estadístico de procesos fisicoquímicos multivariables."
  },
  {
    "objectID": "metodologiayfundamentos.html#comprimir-datos",
    "href": "metodologiayfundamentos.html#comprimir-datos",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "1 ¿Comprimir Datos?",
    "text": "1 ¿Comprimir Datos?\nEn una sección anterior se mencionó que para ser construidos y aplicados de manera confiable, los modelos empíricos multivariables requieren grandes cantidades de datos comprimibles.\nAntes de iniciar, conviene preguntarnos: ¿qué sucede al trabajar formalmente con datos, particularmente cuando son multivariables?\nEl propósito es tomar decisiones acertadas. Para ello, existen dos submetodologías:\n\nEl análisis estadístico (o algorítmico) de los datos.\nEl análisis gráfico de los datos.\n\nAmbas trabajan juntas y para que cumplamos el sentido formal, deben aplicarse en ese orden.\nSin embargo, incluso antes de analizar cualquier conjunto de números y variables, existe un requisito previo que debemos satisfacer y podemos formularlo con una pregunta: ¿cuál es el fundamento metodológico que debemos seguir y respetar para que nuestra labor analítica sea científicamente válida?\nO en términos más coloquiales: ¿cómo vamos a proceder y por qué elegimos hacerlo de esa manera?\nEn el caso concreto de la construcción de procedimientos de control estadístico para procesos fisicoquímicos multivariables, el mecanismo formal ya existe desde hace décadas. Y todo comienza con una tabla de datos que pueden estar conformados por un gran número de observaciones ( \\(N\\) ), un gran número de variables por observación (\\(M\\) ), o por ambos simultáneamente. En el caso de los procesos fisicoquímicos industriales, el número de variables \\(M\\) por observación puede variar desde unas cuantas hasta decenas o incluso cientos.\nCuando el número de variables es elevado, surgen dificultades tanto logísticas como matemáticas al trabajar con datos multivariables. Desde el punto de vista operativo, aumenta la complejidad del almacenamiento, la visualización y la interpretación de la información. Desde el punto de vista matemático, aparecen problemas asociados a la correlación, la redundancia y la inestabilidad numérica de los modelos.\nLa compresión de datos es el proceso mediante el cual un conjunto de datos de alta dimensionalidad se transforma en una representación que utiliza menos variables, pero que conserva, en forma condensada, la mayor parte de la información relevante. Desde una perspectiva estadística, una representación comprimida reduce el número de variables, requiere menos almacenamiento y consume menos recursos computacionales. Desde una perspectiva analítica, permite filtrar información irrelevante, redundante o indeseada, facilitando el desempeño de las técnicas de modelación que se aplican posteriormente.\nExisten múltiples métodos de compresión de datos utilizados en distintas áreas técnicas, como las transformadas de Fourier, las wavelets y métodos afines, ampliamente empleados en espectroscopía, cromatografía y otros problemas analíticos específicos.\nSin embargo, existe un tipo particular de compresión de datos que se ha convertido en el fundamento de los métodos quimiométricos y que resulta especialmente ventajoso para el control estadístico de procesos fisicoquímicos multivariables: el Análisis de Componentes Principales (PCA)."
  },
  {
    "objectID": "metodologiayfundamentos.html#los-detalles-de-pca",
    "href": "metodologiayfundamentos.html#los-detalles-de-pca",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "2 Los detalles de PCA",
    "text": "2 Los detalles de PCA\nLa siguiente terminología y vocabulario pueden resultar nuevos para algunos lectores. Eso está bien porque esta lectura es para ellos y no para especialistas experimentados que la pueden encontrar básica, elemental y aburrida.\nPCA es un método de compresión de datos que se considera rutinario y elemental en estadística multivariable. ¿Qué nos ofrece? Lo que hace es reducir un conjunto de datos obtenido a partir de \\(M\\) variables medidas a lo largo de \\(N\\) observaciones. Esta reducción consiste en producir una representación más simple que, en muchos casos, utiliza un número mucho menor de “variables comprimidas” ( \\(A≪M\\)). En algunos casos la compresión es limitada ( \\(A&lt;M\\) ) y esto es una clara señal de que el control no será alcanzable y la causa es solo una: el proceso no es repetible y la falta de compresión suficiente es evidencia de ello. Si el proceso estuviera en control, los datos se comprimirían.\nEstas variables comprimidas reciben el nombre de componentes principales (PCs).\nLa formulación matemática estándar de PCA se expresa como:\n\n2.1 \\[ \\boldsymbol{X = TP^t + E} \\]Donde:\n\n\\(\\boldsymbol{X}\\) es la matriz de datos original de dimensiones \\(N×M\\)\n\\(\\boldsymbol{T}\\) es una matriz \\(N×A\\) que contiene los scores de los componentes principales\n\\(\\boldsymbol{P}\\) es una matriz \\(M×A\\) que contiene los loadings de los componentes principales\n\\(\\boldsymbol{E}\\) es una matriz \\(N×M\\) de residuales\n\nPara el lector que comienza a explorar esta lectura, los términos y símbolos matemáticos pueden parecer extraños o innecesariamente abstractos. Es importante aclarar desde el inicio que no se trata de nada más que notación básica de álgebra lineal, utilizada para describir algo muy familiar: tablas de datos.\nEn estas tablas, las columnas representan variables y las filas representan valores medidos sucesivamente, una observación tras otra. Esa tabla completa es lo que llamamos la matriz \\(\\boldsymbol{X}\\).\nCada fila de esa matriz contiene todos los valores medidos en un instante, corrida u observación particular. En química analítica, a esto se le suele llamar una corrida. En estadística se le llama observación. En álgebra lineal, se le llama vector. En términos prácticos, todos estos términos describen exactamente lo mismo: una fila de la tabla de datos. Cada celda de esa fila es un dato individual.\nAsí, en términos de nomenclatura:\n\n\\(\\boldsymbol{X}\\) es la matriz de datos completa,\n\\(x_1, x_2, x_3, ... x_n\\) son los vectores (observaciones, corridas) que conforman la muestra multivariable, desde la primera hasta la última.\n\nLa matriz \\(\\boldsymbol{X}\\) no es algo externo al proceso: ella es la muestra. Toda la información disponible sobre el estado del sistema fisicoquímico para construir nuestro procedimiento de control está contenida ahí.\nDespués del tratamiento por PCA, la información contenida en \\(\\boldsymbol{X}\\) se reorganiza en un nuevo conjunto de variables, los componentes principales, que denotamos como \\(A\\).\nEl lector sin experiencia previa no debe perder de vista lo esencial: la información que nos permite evaluar la estabilidad general de un proceso está contenida en la varianza. Todos los cambios fisicoquímicos de interés (reacciones, desviaciones operativas, degradaciones, fallas incipientes) se manifiestan inevitablemente como cambios en los datos, y esos datos siempre terminan organizados en una matriz.\nLas variables originales viven en un espacio euclidiano, donde sus correlaciones y colinealidades están presentes y son visibles. Sin embargo, cuando aplicamos PCA, el análisis de datos y la calibración multivariable ya no ocurren en ese espacio original, sino en lo que se conoce como el espacio ortogonal.\nEn este nuevo espacio, las variables originales son reemplazadas por los componentes principales:\n\n\\(A_1, A_2, A_3... etc\\)\n\nCada uno de estos componentes contiene información de variación del proceso, cuantificada mediante su correspondiente eigenvalor:\n\n\\(\\lambda_1, \\lambda_2, \\lambda_3... etc\\)\n\nCada eigenvalor representa cuánta varianza explica su componente principal asociado. Lo peculiar (y fundamental) es que los componentes principales no están correlacionados entre sí. Esta propiedad es precisamente la que hace a PCA tan atractivo y tan poderoso: el problema de la correlación entre variables prácticamente desaparece.\nMás adelante veremos por qué esta característica es crítica para el monitoreo y control estadístico de procesos.\nDesde un punto de vista operativo:\n\nLos scores pueden interpretarse como las magnitudes de cada una de las variables comprimidas \\(A\\) para todas las observaciones \\(N\\). Es decir, describen cómo se comporta cada observación dentro del espacio PCA. Esta información está contenida en la matriz \\(\\boldsymbol{T}\\).\nLos loadings, por su parte, representan la traducción entre las variables originales \\(M\\) de la matriz \\(\\boldsymbol{X}\\) y los componentes principales \\(A\\). Esta relación está contenida en la matriz \\(\\boldsymbol{P}\\).\n\nEn términos simples, los loadings describen cómo cada componente principal se expresa en función de las variables físicas originales. Son el puente matemático que conecta el espacio abstracto ortogonal con el sistema fisicoquímico material.\nEsta transformación no elimina información ni la distorsiona. La reorganiza. Y esa reorganización es la condición necesaria para que el control estadístico multivariable sea matemáticamente válido, operacionalmente estable y científicamente confiable.\nDesde esta perspectiva, PCA no destruye la información contenida en \\(\\boldsymbol{X}\\), sino que la transforma a un espacio equivalente pero matemáticamente más manejable. Es una conversión desde el espacio original de mediciones físicas a un espacio abstracto donde la información se encuentra reorganizada y desacoplada.\nEn la implementación más común del algoritmo PCA se cumplen dos propiedades fundamentales:\n\nLos loadings de cada componente principal están normalizados y son ortogonales entre sí:\n\n\n\n2.2 \\[\n\\boldsymbol{P^tP = I}\n\\]\n\nLos scores de los componentes principales también son ortogonales entre sí, y su matriz de covarianzas está dada por:\n\n\n\n2.3 \\[\n\\frac{\\mathbf{T}^\\mathsf{T}\\mathbf{T}}{N-1}\n=\n\\operatorname{diag}(\\boldsymbol{\\lambda})\n\\]\ndonde \\(\\boldsymbol{I}\\) es la matriz de identidad y \\(\\boldsymbol{diag⁡(λ)}\\) es una matriz diagonal que contiene los autovalores (eigenvalues) de los componentes principales."
  },
  {
    "objectID": "metodologiayfundamentos.html#qué-significa-todo-esto",
    "href": "metodologiayfundamentos.html#qué-significa-todo-esto",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "3 ¿Qué significa todo esto?",
    "text": "3 ¿Qué significa todo esto?\nVistas desde la estadística clásica, cada variable aporta una cantidad de varianza \\(\\sigma^2\\).\nDe igual manera, cada autovalor \\(\\lambda_a\\)​ representa la cantidad de varianza de los datos originales, pero ahora explicada por el componente principal \\(A\\). Como es natural, la suma de todas las varianza, que en este caso son todos los autovalores, corresponde al 100 % de la varianza total del sistema. Así, un pequeño número de componentes principales puede capturar la mayor parte, o la totalidad de la variabilidad relevante del proceso. Toda la información que nos interesa analizar está contenida ahí.\n¿Cómo?\nConceptualmente, cada variable original \\(X_1, X_2, X_3,..., X_n\\) puede entenderse como un eje en un espacio euclidiano. Al contener muchas variables, se dice que este espacio es de alta dimensión. Algo que sucede de manera natural es que todas las correlaciones entre variables se preservan. Sin embargo, esa misma riqueza estructural introduce colinealidades que vuelven inestables e inválidos muchos modelos estadísticos y eso es justamente lo que obliga a proponer y explorar mecanismos alternativos para procesar y analizar y poder trabajar con nuestros datos en aploicaciones como la construcción de procedimientos de control estadístico. PCA actúa precisamente desacoplando las correlaciones entre estas dimensiones y reorganizando la información en un nuevo sistema de ejes ortogonales.\nAl decir que “se busca desacoplar correlaciones entre variables” el lector rápidamente puede detectar que esto no tendría sentido físico e iría contra toda intuición científica: ¿para qué querríamos eliminar las correlaciones entre variables, si es precisamente allí donde se encuentra nuestra información?\nAunque las nuevas variables (los componentes principales) no tienen significado físico directo, esto no representa una desventaja ni una pérdida de información. Es simplemente el paso de una representación material a una representación matemática. Este diseño permite que los modelos estadísticos funcionen correctamente.\n¿Cómo?\nLa información de la variación, magnitud, orientación y correlación pasa de estar contenida en cada variable original \\(X_n\\), a cada componente pricipal \\(A\\)."
  },
  {
    "objectID": "metodologiayfundamentos.html#cómo-ayuda-esto-al-monitoreo-y-control",
    "href": "metodologiayfundamentos.html#cómo-ayuda-esto-al-monitoreo-y-control",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "4 ¿Cómo ayuda esto al monitoreo y control?",
    "text": "4 ¿Cómo ayuda esto al monitoreo y control?\nEn un contexto de monitoreo y control estadístico de procesos, el uso de PCA es crítico porque permite evitar el problema de intercorrelación. Utilizar componentes principales como variables de monitoreo en lugar de las variables originales en la matriz \\(\\boldsymbol{X}\\) impide:\n\nLa inflación artificial de alarmas causada por variables correlacionadas que se desvían de manera coherente.\nEl enmascaramiento de fallas reales, donde desviaciones pequeñas pero coordinadas pasan desapercibidas en análisis univariables.\nLa violación de supuestos fundamentales de independencia requeridos por los estadísticos clásicos.\nLa pérdida de capacidad diagnóstica al no poder separar variaciones sistemáticas de ruido o de comportamientos fuera del modelo.\nLa dependencia excesiva del criterio subjetivo del operador para interpretar señales múltiples y contradictorias.\n\nEn el espacio PCA, el comportamiento del proceso puede descomponerse formalmente en dos tipos de variación: la variación sistemática capturada por el modelo (medida típicamente con \\(T^2\\)) y la variación no explicada por el modelo (medida con \\(Q\\) o SPE). Esta separación es imposible sin compresión y ortogonalización.\nAntes de PCA, el control se realiza sobre muchas variables colineales, con estadística inválida y resultados frágiles. Después de PCA, el control se realiza sobre pocas variables ortogonales, con estadística válida, interpretación clara y capacidad diagnóstica real.\nNo se trata de simplificar el proceso. Se trata de hacerlo visible.\nNo se trata de perder información. Se trata de organizarla de forma que el control estadístico funcione sin verse afectado por las covarianzas del sistema.\nEn este sentido, PCA no es una opción elegante ni una herramienta académica más. Es una condición necesaria para cualquier sistema serio de monitoreo y diagnóstico estadístico de procesos fisicoquímicos multivariables al operar con componentes principales en lugar de variables originales."
  },
  {
    "objectID": "metodologiayfundamentos.html#los-residuales",
    "href": "metodologiayfundamentos.html#los-residuales",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "5 Los residuales",
    "text": "5 Los residuales\nCuando aplicamos métodos de compresión de datos y seleccionamos únicamente una fracción de la información disponible, esto implica necesariamente ignorar parte de la variación contenida en la matriz de datos originales \\(\\boldsymbol{X}\\). Esa fracción de variación no modelada se almacena en la matriz de residuales, denotada como \\(\\boldsymbol{E}\\).\nUna vez calculada la matriz de scores estimados \\(\\boldsymbol{\\hat{T}}\\) correspondiente a los componentes principales \\(A\\) seleccionados, y la matriz de loadings estimados \\(\\boldsymbol{\\hat{P}}\\) asociada a esos mismos componentes, los residuales (es decir, la parte de los datos que no es explicada por el modelo PCA) se estiman como:\n\n5.1 \\[\n\\boldsymbol{\\hat{E} = X - \\hat{T}\\hat{P}^t}\n\\]\nDesde un punto de vista conceptual, esta ecuación expresa que los datos originales \\(\\boldsymbol{X}\\) se descomponen en dos partes:\n\nUna parte modelada, capturada por el subespacio definido por los \\(A\\) componentes principales seleccionados.\nUna parte no modelada, contenida en los residuales \\(\\boldsymbol{\\hat{E}}\\), que representa variación que el modelo PCA no explica."
  },
  {
    "objectID": "metodologiayfundamentos.html#el-problema-práctico-cuántos-componentes-conservar",
    "href": "metodologiayfundamentos.html#el-problema-práctico-cuántos-componentes-conservar",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "6 El problema práctico: ¿cuántos componentes conservar?",
    "text": "6 El problema práctico: ¿cuántos componentes conservar?\nEn la práctica, surge un desafío central: la decisión de cuántos componentes principales \\(A\\) conservar en el modelo PCA. Esta decisión no es puramente objetiva. Aunque existen reglas heurísticas y criterios estadísticos ampliamente utilizados, la selección de \\(A\\) sigue siendo, en esencia, una decisión de compromiso.\nEl objetivo de esta decisión es equilibrar dos necesidades contrapuestas:\n\nExplicar la mayor cantidad posible de la variación contenida en los datos originales.\nEvitar la inclusión de ruido en el modelo, ya que incorporar demasiados componentes conduce inevitablemente al sobreajuste, es decir, a modelar variación aleatoria que no representa comportamiento estructural del proceso.\n\nUn modelo PCA con pocos componentes puede resultar insuficiente y dejar fuera información relevante del proceso. En cambio, un modelo con demasiados componentes pierde su capacidad de generalización y se vuelve sensible al ruido, lo cual degrada su valor como herramienta de monitoreo y diagnóstico.\nEsta tensión entre explicación y parsimonia es inherente a todos los modelos empíricos multivariables y constituye uno de los puntos críticos en la construcción de calibraciones quimiométricas robustas."
  },
  {
    "objectID": "metodologiayfundamentos.html#el-principal-beneficio-de-pca-en-el-control-estadístico-de-procesos-fisicoquímicos-multivariables",
    "href": "metodologiayfundamentos.html#el-principal-beneficio-de-pca-en-el-control-estadístico-de-procesos-fisicoquímicos-multivariables",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "7 El principal beneficio de PCA en el control estadístico de procesos fisicoquímicos multivariables",
    "text": "7 El principal beneficio de PCA en el control estadístico de procesos fisicoquímicos multivariables\nEn su uso tradicional (y limitado) PCA suele emplearse como una herramienta exploratoria en contextos genéricos de “ciencia de datos”, sin explotar sus capacidades diagnósticas más potentes.\nSin embargo, en un contexto de diagnóstico fisicoquímico aplicado al control estadístico de procesos multivariables, gobernados por sensores, actuadores electrónicos y tecnologías analíticas de proceso (PAT), PCA se convierte en una herramienta de predicción de la estabilidad del proceso de transformación fisicoquímica.\nUn caso típico de esta aplicación ocurre cuando se desea determinar si los datos obtenidos en tiempo presente son aceptables o inaceptables al compararlos contra un conjunto de referencia utilizado para construir una calibración multivariable.\nLas decisión es simple porque es binaria: si los datos son aceptables, el proceso continúa. De lo contrario, se requiere intervención."
  },
  {
    "objectID": "metodologiayfundamentos.html#cómo-se-realiza-este-procedimiento",
    "href": "metodologiayfundamentos.html#cómo-se-realiza-este-procedimiento",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "8 ¿Cómo se realiza este procedimiento?",
    "text": "8 ¿Cómo se realiza este procedimiento?\nEl enfoque correcto consiste en construir un modelo PCA utilizando una cantidad suficiente de observaciones multivariables provenientes de un conjunto de datos de referencia que represente condiciones operativas normales del proceso y cuya producción cumpla con los criterios de conformidad del producto.\nUna vez construido el modelo, este se aplica a nuevas corridas de datos \\(\\boldsymbol{x}\\)​ conocidas individualmente como el “perfil analítico” y que son generadas conforme el proceso continúa en operación.\nEste procedimiento exige una secuencia de pasos bien definida, es decir, un algoritmo y que se puede programar fácilmente en una computadora.\n\n8.1 Preprocesamiento del nuevo vector\nCada nuevo vector de observación debe ser preprocesado mediante autoescalamiento. El procedimiento consiste en restar el vector medio \\(\\boldsymbol{\\bar{x}}\\) y dividir entre el vector de desviaciones estándar \\(\\boldsymbol{s}\\), para obtener:\n\n\n8.2 \\[\n\\boldsymbol{x_p = \\frac{x - \\bar{x}}s}\n\\]\n\n\n8.3 Proyección al espacio PCA\nEl siguiente paso es proyectar el nuevo vector escalado \\(\\boldsymbol{x}_p\\)​ al espacio del modelo PCA mediante los loadings \\(\\boldsymbol{P}\\):\n\n\n8.4 \\[\n\\boldsymbol{\\hat{t}_p} = \\boldsymbol{x_p}\\boldsymbol{P}\n\\]\nEn álgebra lineal, esta operación se conoce como la proyección de la observación al subespacio PCA.\n\n\n8.5 Reconstrucción y cálculo del residual\nUna vez obtenidos los scores proyectados y contenidos en el vector \\(\\boldsymbol{\\hat{t}_p}\\), nuestro algoritmo ahora calcula la respuesta \\(\\boldsymbol{\\hat{x}_p}\\) estimada por el modelo PCA:\n\n\n8.6 \\[ \\boldsymbol{\\hat{x}_p} = \\boldsymbol{\\hat{t}_p}\\boldsymbol{P} \\]\nEl residual \\(\\boldsymbol{\\hat{e}_p}\\) asociado a la nueva observación se obtiene entonces como:\n\n\n8.7 \\[\n\\boldsymbol{\\hat{e}_p = x_p - \\hat{x}_p}\n\\]\nConceptualmente, el residual representa la porción de la medición multivariable que el modelo PCA no puede explicar. Si el modelo explicara también esta fracción, estaría modelando ruido y conduciría inevitablemente al sobreajuste."
  },
  {
    "objectID": "metodologiayfundamentos.html#métricas-de-diagnóstico-t2-y-q",
    "href": "metodologiayfundamentos.html#métricas-de-diagnóstico-t2-y-q",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "9 Métricas de diagnóstico: \\(T^2\\) y \\(Q\\)",
    "text": "9 Métricas de diagnóstico: \\(T^2\\) y \\(Q\\)\nEl propósito de estos cálculos es reconocer que tanto los scores \\(\\boldsymbol{\\hat{t}}_p\\)​ como los residuales \\(\\boldsymbol{\\hat{e}}_p\\) constituyen métricas de predicción. A partir de ellos se construyen dos estadísticos fundamentales para la evaluación de la calidad y la detección válida de anomalías en procesos fisicoquímicos.\n\n9.1 Estadístico \\(T^2\\) de Hotelling\nEn aplicaciones industriales de transformaciones fisicoquímicas (tal como se presenta en la literatura quimiométrica especializada) el estadístico \\(T^2\\) adopta una forma que, aunque algebraicamente equivalente a la definición clásica de la estadística multivariable genérica, resulta operacionalmente más adecuada para su implementación en sistemas de monitoreo. Puede expresarse de dos maneras equivalentes:\n\n\n9.2 \\[ \\boldsymbol{T^2 = \\hat{t}_p * diag(\\lambda)^{-1} * \\hat{t}^t_p} \\]\ny, de forma escalar,\n\n\n9.3 \\[ \\boldsymbol{T^2 = \\Sigma^A_{a=1} \\frac{t^2_a}{\\lambda_a}} \\]\ndonde \\(\\lambda_a\\)​ representa la varianza asociada al componente principal \\(A\\).\n\n\n9.4 Estadístico de residuales \\(Q\\)\nDe manera análoga, el estadístico de residuales \\(Q\\) (también conocido como Squared Prediction Error (SPE)) puede definirse de dos formas equivalentes:\n\n\n9.5 \\[ \\boldsymbol{Q = \\hat{e}_p *\\hat{e}^t_p} \\]\no bien,\n\n\n9.6 \\[ \\boldsymbol{Q = \\Sigma^J_{j=1} {e^2_{ij}}} \\]\n\n\n9.7 Interpretación conjunta\nDesde un punto de vista conceptual, el estadístico \\(T^2\\) mide la lejanía multivariable de una observación dentro del subespacio modelado por el PCA, mientras que el estadístico \\(Q\\) cuantifica la cantidad de variación que queda fuera de dicho subespacio, comúnmente interpretada como falta de ajuste.\nEs completamente válido interpretar la varianza total de un sistema estocástico como una suma que representa el 100% de la información disponible. En este sentido, los estadísticos \\(T^2\\) y \\(Q\\) capturan fracciones complementarias de esa misma varianza total. No se trata de omitir información, sino precisamente de procesarla en su totalidad.\nPor esta razón, ambos estadísticos son necesarios para una evaluación completa de las anomalías detectables durante la operación del proceso:\n\n\\(T^2\\) concentra toda la variación dentro del modelo PCA,\nmientras que \\(Q\\) captura toda la variación que queda fuera de él."
  },
  {
    "objectID": "metodologiayfundamentos.html#límites-de-confianza-y-lanzamiento-del-procedimiento-de-control",
    "href": "metodologiayfundamentos.html#límites-de-confianza-y-lanzamiento-del-procedimiento-de-control",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "10 Límites de confianza y lanzamiento del procedimiento de control",
    "text": "10 Límites de confianza y lanzamiento del procedimiento de control\nAntes de operar un modelo PCA como herramienta de monitoreo, es necesario y obligatorio establecer límites de confianza que funcionen como límites de control para ambos estadísticos de diagnóstico: \\(T^2\\) y \\(Q\\).\nExisten diversos métodos para determinar estos límites; sin embargo, en términos generales, todos requieren dos elementos fundamentales:\n\nLos valores de \\(T^2\\) y \\(Q\\) obtenidos a partir del conjunto de calibración, es decir, de datos que representan condiciones operativas aceptables del proceso.\nLa especificación explícita del nivel de confianza deseado (95%, 99%, 99.9%, etc.), el cual es definido por el cliente en función del compromiso requerido entre sensibilidad (capacidad de detección de anomalías) y especificidad (evitar falsas alarmas) del sistema de monitoreo.\n\nUna vez que estos límites han sido calibrados y que la robustez del modelo PCA ha sido validada, el modelo puede desplegarse formalmente como un procedimiento de control estadístico multivariable, capaz de detectar outliers en tiempo real durante la operación normal del proceso.\nLa obra de J. Edward Jackson, A User’s Guide to Principal Components, resulta particularmente ilustrativa en este contexto para los profesionales de la química industrial aplicada. El propio Jackson reconoce que gran parte del desarrollo práctico de estas metodologías surgió durante su trabajo en la industria química de Kodak desde la década de los 40s, en estrecha colaboración con químicos interesados en el desarrollo de herramientas estadísticas avanzadas, para aplicarlas al control y mejora de la calidad de productos químicos.\nJackson enfatiza que el límite de control del estadístico \\(T^2\\) está íntimamente relacionado con la distribución de probabilidad \\(F\\), y se calcula como:\n\n10.1 \\[\n\\boldsymbol{T^2_{p, n, \\alpha} = \\frac{p(n-1)}{n - p} F_{p, n-p, \\alpha}}\n\\]\ndonde \\(\\boldsymbol{p}\\) es el número de componentes principales retenidos en el modelo, \\(\\boldsymbol{n}\\) es el número de observaciones de calibración y \\(\\boldsymbol{\\alpha}\\) es el nivel de significancia seleccionado.\nDe manera análoga, Jackson presenta la expresión para el valor crítico del estadístico residual \\(\\boldsymbol{Q}\\):\n\n\n10.2 \\[\n\\boldsymbol{Q_\\alpha = \\theta_1 [\\frac{c_\\alpha\\sqrt{2\\theta_2h^2_0}}{\\theta_1} +\\frac{\\theta_2h_0(h_0-1)}{\\theta^2_1} + 1]^{t/h_0}}\n\\]\ndonde los términos \\(\\boldsymbol{\\theta_1}\\)​, \\(\\boldsymbol{\\theta_2}\\)​ y \\(\\boldsymbol{h_0}\\)​ dependen de los eigenvalores no incluidos en el modelo, y \\(\\boldsymbol{c_\\alpha}\\)​ es un valor crítico asociado a una distribución aproximadamente normal.\nJackson hace una aclaración particularmente relevante desde el punto de vista industrial: la aproximación normal de \\(\\boldsymbol{c_\\alpha}\\)​ es válida independientemente de si se han incluido o no todos los componentes principales estadísticamente significativos en el modelo PCA. Esta propiedad refuerza de manera decisiva la utilidad práctica del estadístico \\(\\boldsymbol{Q}\\) como una métrica robusta para el monitoreo de procesos reales, donde la parsimonia del modelo es tan importante como su capacidad de detección.\nEn conjunto, estos límites de confianza constituyen el paso final que coloca a los modelos PCA en su debido y justo lugar: dejan de ser un simple “algoritmo de aprendizaje no supervisado”, una desafortunada descripción que surge de la perspectiva reduccionista de la popularmente llamada ciencia de datos. En ese ámbito, los modelos PCA suelen interpretarse como un procedimiento intermedio y arcaico, una herramienta descriptiva primitiva de patrones pero no de conclusiones, en la que el significado material y la interpretabilidad de los datos supuestamente “se pierden”.\nPara la industria química, en cambio, los modelos PCA se revelan y prevalecen como lo que verdaderamente son: sistemas analíticos formales de datos de medición para el control estadístico multivariable de procesos fisicoquímicos, matemáticamente trazables, operacionalmente robustos y plenamente auditables, precisamente porque están rigurosamente fundamentados en el álgebra lineal.\nLos algoritmos genéricos de machine learning promovidos desde la ciencia de datos no pueden ofrecer un nivel comparable de escrutinio metodológico ni de trazabilidad matemática.\nSe trata, en el caso del PCA, de sistemas diseñados con transparencia para su despliegue y monitoreo continuo en entornos industriales reales, capaces de informar (observación tras observación) la estabilidad operativa de las relaciones vinculantes entre todas las variables del proceso.\nNo existe un método más riguroso, transparente y libre de cajas negras para asegurar la calidad del producto y garantizar la satisfacción del cliente."
  },
  {
    "objectID": "metodologiayfundamentos.html#el-diagnóstico-de-causas-raíz",
    "href": "metodologiayfundamentos.html#el-diagnóstico-de-causas-raíz",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "11 El diagnóstico de causas raíz",
    "text": "11 El diagnóstico de causas raíz\nNo obstante, para que un procedimiento de control estadístico multivariable sea verdaderamente completo, es indispensable atender la siguiente pregunta fundamental:\n¿Cuál o cuáles variables causaron la desviación observada?\nEl mecanismo quimiométrico diseñado específicamente para responder esta pregunta son las contribuciones \\(t\\) y las contribuciones \\(q\\).\nEs precisamente en este punto donde el proceso deja de comportarse como una caja negra (como ocurre con muchos algoritmos de machine learning) y comienza a explicarse a sí mismo, proporcionando información diagnóstica interpretable desde el punto de vista fisicoquímico.\nEs importante aclarar que, en el desarrollo de modelos PCA para el control estadístico multivariable de procesos fisicoquímicos, existen dos tipos claramente diferenciados de outliers:\n\nOutliers presentes durante la etapa de calibración del modelo, los cuales pueden conducir al desarrollo de modelos multivariables subóptimos si no son identificados y tratados adecuadamente.\nOutliers detectados durante la etapa de operación (despliegue) del modelo, los cuales pueden resultar igual o incluso más dañinos.\n\nEsto último ocurre porque cualquier resultado de predicción será necesariamente inválido al obtenerlo tras aplicar un modelo empírico a una nueva observación que proviene de un estado fisicoquímico extraño, es decir, no representado y por tanto desconocido en los datos de calibración.\nCualquier intento de aplicar un modelo de calibración multivariable a observaciones nuevas en tales estados inapropiados resultará en predicciones evidentemente inexactas.\nComo consecuencia, es crítico evaluar continuamente si las muestras provenientes del proceso de transformación son aptas para su uso con el modelo empírico. En modelos construidos mediante PCA, PLS, PCR u otros métodos basados en factores latentes, el mecanismo convencional para este tipo de monitores de salud del modelo se encuentra intrínsecamente incorporado en el propio modelo de calibración.\nTanto durante la calibración como durante la operación del método, un valor anormalmente elevado del estadístico \\(T^2\\) indica que la observación exhibe una conducta irregular que aún reside dentro del espacio multivariado del modelo, pero en una región distante de las observaciones típicas que definen el modelo de calibración PCA contra el cual se comparan las nuevas observaciones generadas por el proceso.\nEn contraste, un valor residual \\(Q\\) anormalmente elevado indica que la observación contiene información significativamente distinta a la capturada por el modelo PCA de calibración, es decir, información que no puede ser explicada por los componentes principales retenidos.\nEn cualquiera de ambos casos, cualquier resultado generado a partir de una observación que presente valores elevados de \\(T^2\\) y/o \\(Q\\) debe considerarse una predicción inválida.\nDurante la operación real de procesos industriales, el número de observaciones multivariables fácilmente supera las decenas o centenas. Dado el volumen de cálculo involucrado, el tiempo limitado disponible y la inevitable presencia de error humano, su monitoreo debe ser automatizado mediante software especializado. Nunca debe realizarse de forma manual ni con plantillas configuradas en software genérico de hojas de cálculo. El riesgo de error en el cómputo y de configuraciones frágiles en el diseño del algoritmo es demasiado elevado.\nEl uso de \\(T^2\\) y \\(Q\\) como métricas para la detección de outliers en el control estadístico de procesos multivariables fisicoquímicos constituye un claro ejemplo de monitores de salud del sistema bajo observación. Estas métricas emergen directamente de un modelo de predicción (ya sea PCA, PLS o PCR) y establecen el estándar cuantitativo contra el cual cada nueva observación es comparada, permitiendo una decisión binaria: aceptar o rechazar la observación, y actuar en consecuencia.\nPor esta razón, en quimiometría, \\(T^2\\) y \\(Q\\) son consideradas las métricas de élite en la detección de anomalías.\nAdicionalmente, para cualquier nueva observación que produzca valores elevados o sospechosos de \\(T^2\\) y/o \\(Q\\), es posible calcular las contribuciones individuales de cada variable fisicoquímica que impactan dichos estadísticos. Estas reciben el nombre de contribuciones \\(t\\) y contribuciones \\(q\\), cuyas definiciones son:\n\n11.1 \\[\n\\boldsymbol{t_{cont} = \\hat{t}_p \\lambda^{1/2} P^t}\n\\]\n\n\n11.2 \\[\n\\boldsymbol{q_{cont} = \\hat{e}_p}\n\\]\nEstas contribuciones resultan particularmente útiles para evaluar la naturaleza específica de la causa (o causas) de la anomalía detectada durante el monitoreo del proceso.\nEl objetivo es único y claro:\nSi se desea determinar la naturaleza específica o las causas raíz de observaciones anómalas, entonces las contribuciones \\(t\\) y \\(q\\) asociadas a aquellas lecturas donde se observaron valores elevados de \\(T^2\\) y \\(Q\\) proporcionan la información diagnóstica más poderosa y útil disponible actualmente en la ciencia quimiométrica."
  },
  {
    "objectID": "metodologiayfundamentos.html#conclusión",
    "href": "metodologiayfundamentos.html#conclusión",
    "title": "La necesidad de comprimir datos en control estadístico multivariable",
    "section": "12 Conclusión",
    "text": "12 Conclusión\nTras esta exposición, el lector podría concluir que el rigor matemático aquí presentado pertenece exclusivamente al ámbito académico o al ejercicio teórico dentro del aula. Ese criterio es incorrecto.\nNada de lo expuesto corresponde a una teoría fisicoquímica. Todo el desarrollo presentado constituye, en realidad, la base estrictamente matemático-estadística necesaria para construir algoritmos programables destinados a la producción de software de monitoreo en tiempo real. En ese contexto, la aplicación resuelve el único problema industrial que verdaderamente importa:\nEl aseguramiento objetivo y continuo de la calidad del producto para la satisfacción del cliente.\nEsto exige la definición de una regla de decisión clara, binaria y auditable:\nAceptación o rechazo de una observación, y la identificación de sus causas.\n¿Y qué hace que dicha decisión sea auditable?\n\nLa trazabilidad matemática completa del método que da origen al modelo.\nLa expresión gráfica y visual que permite rapidez y claridad intuitiva al tomar cada decisión.\n\nFundamentar y demostrar cada decisión tomada bajo un mecanismo que permita justificarla sin ambigüedades, sin arbitrariedades y sin subjetividades es lo que protege la reputación profesional. No existe otra forma. (Si el lector conoce alguna alternativa igualmente rigurosa, le pedimos que nos la haga saber; nos interesaría enormemente conocerla).\nPor esta razón, en un contexto de control estadístico multivariable de procesos, los algoritmos genéricos de machine learning no constituyen una opción responsable ni científica: al operar como cajas negras, el escrutinio de la interacción entre variables queda oculto, y la rendición de cuentas con transparencia metodológica se vuelve imposible.\nEsto no significa que los algoritmos de machine learning ofrecidos por la ciencia de datos carezcan de utilidad industrial. Todo lo contrario: su capacidad predictiva puede ser notable. Su limitación fundamental es otra: no son matemáticamente transparentes, ni pueden serlo, porque no han sido diseñados con ese propósito.\nAl final, el lector elige:\n\nmetodologías multivariables reconocidas, trazables y abiertas;\nmetodologías multivariables novedosas, genéricas y cerradas;\no una combinación consciente y responsable de ambas.\n\nPor estas razones, esta exposición no debe interpretarse como un ejercicio teórico-académico, sino como lo que realmente es:\nUna metodología estrictamente aplicada para la industria de transformaciones fisicoquímicas, diseñada para operar procesos reales bajo condiciones reales, con criterios objetivos, reproducibles, defendibles y plenamente auditables.\nInvitamos al lector a enviarnos sus comentarios, preguntas y sugerencias."
  },
  {
    "objectID": "Q.html",
    "href": "Q.html",
    "title": "Exploración Multivariada - Q de Jackson",
    "section": "",
    "text": "El gráfico Q (Squared Prediction Error) de Jackson permite vigilar un proceso multivariable desde otra perspectiva complementaria a T².\nCada punto representa un lote completo (o un instante temporal del lote): la energía residual, es decir, la parte del comportamiento del sistema no explicada por el modelo multivariable dominante.\nEn calibraciones avanzadas, Q puede evaluarse a lo largo del tiempo, revelando cuándo el proceso empieza a comportarse de una manera estructuralmente distinta a lo aprendido en la fase histórica.\nLa pregunta es distinta, pero igualmente fundamental:\n¿Este lote (o instante temporal) sigue perteneciendo al mismo sistema que fue modelado?\n\n\n\n\n\n\n\n\nQ mide la variación residual, aquello que queda fuera del subespacio del modelo.\n\nQ bajo → comportamiento consistente con la estructura conocida de las variables\nQ alto → comportamiento no explicado por el modelo\n\nQ no mide intensidad del proceso.\nMide incongruencia estructural, novedad o extrañeza multivariable.\nUn Q elevado indica posibles:\n\nperturbaciones externas,\nfallas incipientes,\ncambios de formulación o de régimen,\ncondiciones operativas no modeladas.\n\n\n\n\nEn una secuencia de producción:\n\ncada punto es un lote, (o un instante durante su evolución),\nel eje vertical es Q,\nel eje horizontal es la secuencia temporal,\nel límite superior define la frontera de pertenencia al modelo.\n\nUn cruce del límite Q indica que el proceso ya no se comporta como el sistema fue calibrado, aun cuando a simple vista algunas variables individuales parezcan normales.\nEsto puede sonar abstracto, así que ilustrémoslo: si 20 lotes se aproximan al perfil original y todos son conformes, pero el lote 21, aunque sea aceptable pero no necesariamente rechazable, su perfil será diferente y Q lo informará. Dependerá del analista decidir si esa diferencia es materialmente relevante, aunque haya sido estadísticamente significativa.\nEsto exige diagnóstico estructural (con nuestro método y tecnología, también es inmediato).\n\n\n\n✔ Detecta comportamientos nuevos o no modelados\n✔ Revela cambios de naturaleza del proceso\n✘ No cuantifica intensidad dentro del modelo (eso es T²)\nQ no sustituye a T² ni al SPC univariable:\nComplementa el monitoreo revelando cuándo el proceso deja de ser el mismo.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q",
      "3.3 Jackson Q / SPE"
    ]
  },
  {
    "objectID": "Q.html#gráfico-q-spe-monitoreo-de-comportamiento-no-modelado",
    "href": "Q.html#gráfico-q-spe-monitoreo-de-comportamiento-no-modelado",
    "title": "Exploración Multivariada - Q de Jackson",
    "section": "",
    "text": "El gráfico Q (Squared Prediction Error) de Jackson permite vigilar un proceso multivariable desde otra perspectiva complementaria a T².\nCada punto representa un lote completo (o un instante temporal del lote): la energía residual, es decir, la parte del comportamiento del sistema no explicada por el modelo multivariable dominante.\nEn calibraciones avanzadas, Q puede evaluarse a lo largo del tiempo, revelando cuándo el proceso empieza a comportarse de una manera estructuralmente distinta a lo aprendido en la fase histórica.\nLa pregunta es distinta, pero igualmente fundamental:\n¿Este lote (o instante temporal) sigue perteneciendo al mismo sistema que fue modelado?\n\n\n\n\n\n\n\n\nQ mide la variación residual, aquello que queda fuera del subespacio del modelo.\n\nQ bajo → comportamiento consistente con la estructura conocida de las variables\nQ alto → comportamiento no explicado por el modelo\n\nQ no mide intensidad del proceso.\nMide incongruencia estructural, novedad o extrañeza multivariable.\nUn Q elevado indica posibles:\n\nperturbaciones externas,\nfallas incipientes,\ncambios de formulación o de régimen,\ncondiciones operativas no modeladas.\n\n\n\n\nEn una secuencia de producción:\n\ncada punto es un lote, (o un instante durante su evolución),\nel eje vertical es Q,\nel eje horizontal es la secuencia temporal,\nel límite superior define la frontera de pertenencia al modelo.\n\nUn cruce del límite Q indica que el proceso ya no se comporta como el sistema fue calibrado, aun cuando a simple vista algunas variables individuales parezcan normales.\nEsto puede sonar abstracto, así que ilustrémoslo: si 20 lotes se aproximan al perfil original y todos son conformes, pero el lote 21, aunque sea aceptable pero no necesariamente rechazable, su perfil será diferente y Q lo informará. Dependerá del analista decidir si esa diferencia es materialmente relevante, aunque haya sido estadísticamente significativa.\nEsto exige diagnóstico estructural (con nuestro método y tecnología, también es inmediato).\n\n\n\n✔ Detecta comportamientos nuevos o no modelados\n✔ Revela cambios de naturaleza del proceso\n✘ No cuantifica intensidad dentro del modelo (eso es T²)\nQ no sustituye a T² ni al SPC univariable:\nComplementa el monitoreo revelando cuándo el proceso deja de ser el mismo.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q",
      "3.3 Jackson Q / SPE"
    ]
  },
  {
    "objectID": "T2.html",
    "href": "T2.html",
    "title": "Exploración Multivariada - T2 de Hotelling",
    "section": "",
    "text": "El gráfico T² de Hotelling permite vigilar un proceso multivariable observación por observación.\nCada punto representa un lote completo: todas las variables fisicoquímicas colapsadas en una sola distancia estadística.\nEn calibraciones avanzadas (y las más informativas), cada punto puede representar un instante en el tiempo durante la evolución del lote, desde su inicio hasta su final.\nLa pregunta es simple:\n¿Este lote (o este instante temporal) se comporta como el proceso históricamente estable espera que se comporte?\n\n\n\n\n\n\n\n\nT² mide la distancia multivariable al centro del proceso, considerando simultáneamente todas las variables y sus correlaciones.\n\nT² bajo → lote (o instante temporal) conforme\nT² alto → desviación estructurada del proceso\n\nNo evalúa variables individuales.\nEvalúa el sistema como conjunto.\n\n\n\nEn una secuencia de producción:\n\ncada punto es un lote, o un momento durante su evolución,\nel eje vertical es T²,\nel eje horizontal es la secuencia temporal,\nel límite superior define el control multivariable.\n\nUn cruce del límite T² indica que la combinación completa de variables ya no es consistente con el estado normal del proceso. Esto exige el diagnóstico de causas-raíz (con nuestro método y tecnología esto es con un clic).\n\n\n\n✔ Detecta desviaciones multivariables tempranas\n✔ Integra toda la información del proceso\n✘ No identifica la causa raíz (eso viene después)\nT² no reemplaza al SPC univariable:\nDetecta desviaciones sistémicas más rápido cuando el proceso es multivariable.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q",
      "3.2 Hotelling T²"
    ]
  },
  {
    "objectID": "T2.html#gráfico-t²-monitoreo-multivariable-lote-por-lote",
    "href": "T2.html#gráfico-t²-monitoreo-multivariable-lote-por-lote",
    "title": "Exploración Multivariada - T2 de Hotelling",
    "section": "",
    "text": "El gráfico T² de Hotelling permite vigilar un proceso multivariable observación por observación.\nCada punto representa un lote completo: todas las variables fisicoquímicas colapsadas en una sola distancia estadística.\nEn calibraciones avanzadas (y las más informativas), cada punto puede representar un instante en el tiempo durante la evolución del lote, desde su inicio hasta su final.\nLa pregunta es simple:\n¿Este lote (o este instante temporal) se comporta como el proceso históricamente estable espera que se comporte?\n\n\n\n\n\n\n\n\nT² mide la distancia multivariable al centro del proceso, considerando simultáneamente todas las variables y sus correlaciones.\n\nT² bajo → lote (o instante temporal) conforme\nT² alto → desviación estructurada del proceso\n\nNo evalúa variables individuales.\nEvalúa el sistema como conjunto.\n\n\n\nEn una secuencia de producción:\n\ncada punto es un lote, o un momento durante su evolución,\nel eje vertical es T²,\nel eje horizontal es la secuencia temporal,\nel límite superior define el control multivariable.\n\nUn cruce del límite T² indica que la combinación completa de variables ya no es consistente con el estado normal del proceso. Esto exige el diagnóstico de causas-raíz (con nuestro método y tecnología esto es con un clic).\n\n\n\n✔ Detecta desviaciones multivariables tempranas\n✔ Integra toda la información del proceso\n✘ No identifica la causa raíz (eso viene después)\nT² no reemplaza al SPC univariable:\nDetecta desviaciones sistémicas más rápido cuando el proceso es multivariable.",
    "crumbs": [
      "¿Análisis Multivariable para Procesos Industriales?",
      "3. Diagnóstico T² y Q",
      "3.2 Hotelling T²"
    ]
  }
]